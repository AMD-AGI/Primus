# Primus CLI Examples - Quick Start Guide

æœ¬æ–‡æ¡£ä»‹ç»å¦‚ä½•ä½¿ç”¨ Primus CLI ç¤ºä¾‹è„šæœ¬è¿›è¡Œæ¨¡å‹è®­ç»ƒã€‚

## ğŸ“š æ¦‚è¿°

Primus æä¾›äº†ä¸‰ç§è®­ç»ƒæ¨¡å¼çš„ç¤ºä¾‹è„šæœ¬ï¼š

| è„šæœ¬ | æ¨¡å¼ | é€‚ç”¨åœºæ™¯ |
|------|------|----------|
| `run_pretrain_cli.sh` | Direct | ç›´æ¥åœ¨ä¸»æœºä¸Šè¿è¡Œï¼Œæ— å®¹å™¨å¼€é”€ |
| `run_local_pretrain_cli.sh` | Container | ä½¿ç”¨ Docker/Podman å®¹å™¨ï¼Œç¯å¢ƒéš”ç¦» |
| `run_slurm_pretrain_cli.sh` | Slurm | é›†ç¾¤ç¯å¢ƒï¼Œå¤šèŠ‚ç‚¹è®­ç»ƒ |

---

## 1ï¸âƒ£ Direct Mode - ç›´æ¥æ¨¡å¼

**é€‚ç”¨åœºæ™¯**: åœ¨å·²é…ç½®å¥½çš„ç¯å¢ƒä¸­å¿«é€Ÿæµ‹è¯•å’Œè®­ç»ƒ

### ä½¿ç”¨æ–¹æ³•

```bash
# åŸºæœ¬ä½¿ç”¨
EXP=examples/megatron/exp_pretrain.yaml bash examples/run_pretrain_cli.sh

# æˆ–è€…å…ˆå¯¼å‡ºç¯å¢ƒå˜é‡
export EXP=examples/megatron/exp_pretrain.yaml
bash examples/run_pretrain_cli.sh
```

### å¿…éœ€å‚æ•°

- `EXP`: å®éªŒé…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¿…é¡»å­˜åœ¨ï¼‰

### ç¤ºä¾‹

```bash
# Megatron è®­ç»ƒ
export EXP=examples/megatron/exp_pretrain.yaml
bash examples/run_pretrain_cli.sh

# è‡ªå®šä¹‰é…ç½®
export EXP=my_experiments/custom_config.yaml
bash examples/run_pretrain_cli.sh
```

---

## 2ï¸âƒ£ Container Mode - å®¹å™¨æ¨¡å¼

**é€‚ç”¨åœºæ™¯**: éœ€è¦ç¯å¢ƒéš”ç¦»ï¼Œæˆ–ä½¿ç”¨ç‰¹å®šçš„ Docker é•œåƒ

### ä½¿ç”¨æ–¹æ³•

```bash
# åŸºæœ¬ä½¿ç”¨ (PyTorch)
bash examples/run_local_pretrain_cli.sh

# MaxText/JAX è®­ç»ƒ
BACKEND=MaxText bash examples/run_local_pretrain_cli.sh
```

### ç¯å¢ƒå˜é‡

| å˜é‡ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `EXP` | `examples/megatron/exp_pretrain.yaml` | å®éªŒé…ç½®æ–‡ä»¶ |
| `BACKEND` | (ç©ºï¼Œä½¿ç”¨ PyTorch) | è®¾ç½®ä¸º `MaxText` ä½¿ç”¨ JAX é•œåƒ |
| `DOCKER_IMAGE` | PyTorch: `docker.io/rocm/primus:v25.10`<br>MaxText: `docker.io/rocm/jax-training:maxtext-v25.9` | Docker é•œåƒ |
| `DATA_PATH` | `$(pwd)/data` | æ•°æ®ç›®å½•ï¼ˆè‡ªåŠ¨æŒ‚è½½åˆ°å®¹å™¨ï¼‰ |
| `MASTER_ADDR` | `localhost` | ä¸»èŠ‚ç‚¹åœ°å€ |
| `MASTER_PORT` | `1234` | ä¸»èŠ‚ç‚¹ç«¯å£ |
| `NNODES` | `1` | èŠ‚ç‚¹æ•°é‡ |
| `NODE_RANK` | `0` | å½“å‰èŠ‚ç‚¹ç¼–å· |
| `GPUS_PER_NODE` | `8` | æ¯èŠ‚ç‚¹ GPU æ•°é‡ |

### ç¤ºä¾‹

#### åŸºæœ¬ä½¿ç”¨

```bash
# PyTorch è®­ç»ƒ
bash examples/run_local_pretrain_cli.sh

# æŒ‡å®šé…ç½®æ–‡ä»¶
EXP=examples/megatron/exp_pretrain.yaml \
bash examples/run_local_pretrain_cli.sh
```

#### MaxText/JAX è®­ç»ƒ

```bash
# ä½¿ç”¨ MaxText åç«¯
BACKEND=MaxText \
EXP=examples/maxtext/exp_config.yaml \
bash examples/run_local_pretrain_cli.sh
```

#### è‡ªå®šä¹‰é•œåƒå’Œæ•°æ®è·¯å¾„

```bash
# ä½¿ç”¨è‡ªå®šä¹‰ Docker é•œåƒ
DOCKER_IMAGE=my-registry.com/custom-image:v1.0 \
DATA_PATH=/mnt/shared/datasets \
bash examples/run_local_pretrain_cli.sh
```

#### å¤šèŠ‚ç‚¹è®­ç»ƒï¼ˆæœ¬åœ°å¤šå®¹å™¨ï¼‰

```bash
# Node 0
NNODES=2 NODE_RANK=0 MASTER_ADDR=192.168.1.100 \
bash examples/run_local_pretrain_cli.sh

# Node 1
NNODES=2 NODE_RANK=1 MASTER_ADDR=192.168.1.100 \
bash examples/run_local_pretrain_cli.sh
```

---

## 3ï¸âƒ£ Slurm Mode - é›†ç¾¤æ¨¡å¼

**é€‚ç”¨åœºæ™¯**: ä½¿ç”¨ Slurm ç®¡ç†çš„é›†ç¾¤ç¯å¢ƒï¼Œå¤šèŠ‚ç‚¹åˆ†å¸ƒå¼è®­ç»ƒ

### ä½¿ç”¨æ–¹æ³•

```bash
# åŸºæœ¬ä½¿ç”¨
bash examples/run_slurm_pretrain_cli.sh

# æŒ‡å®šèŠ‚ç‚¹æ•°å’ŒèŠ‚ç‚¹åˆ—è¡¨
NNODES=4 NODES_LIST="node[01-04]" \
bash examples/run_slurm_pretrain_cli.sh
```

### ç¯å¢ƒå˜é‡

| å˜é‡ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `EXP` | `examples/megatron/exp_pretrain.yaml` | å®éªŒé…ç½®æ–‡ä»¶ |
| `NNODES` | `1` | ä½¿ç”¨çš„èŠ‚ç‚¹æ•°é‡ |
| `NODES_LIST` | `node[02,03,10,14,15,34,38]` | Slurm èŠ‚ç‚¹åˆ—è¡¨ |
| `MASTER_PORT` | `12345` | ä¸»èŠ‚ç‚¹ç«¯å£ |
| `LOG_DIR` | `./output` | æ—¥å¿—è¾“å‡ºç›®å½• |

### ç¤ºä¾‹

#### å•èŠ‚ç‚¹è®­ç»ƒ

```bash
# ä½¿ç”¨é»˜è®¤é…ç½®
bash examples/run_slurm_pretrain_cli.sh
```

#### å¤šèŠ‚ç‚¹è®­ç»ƒ

```bash
# 4 èŠ‚ç‚¹è®­ç»ƒ
export NNODES=4
export NODES_LIST="node[01-04]"
export EXP=examples/megatron/exp_pretrain.yaml
bash examples/run_slurm_pretrain_cli.sh
```

#### æŒ‡å®šæ—¥å¿—ç›®å½•

```bash
# è‡ªå®šä¹‰æ—¥å¿—ç›®å½•
LOG_DIR=/shared/experiments/run_001 \
NNODES=8 \
NODES_LIST="gpu[01-08]" \
bash examples/run_slurm_pretrain_cli.sh
```

#### å®Œæ•´ç¤ºä¾‹

```bash
#!/bin/bash
# my_training_job.sh

# è®¾ç½®å®éªŒé…ç½®
export EXP=experiments/llama3_8b.yaml

# é›†ç¾¤é…ç½®
export NNODES=16
export NODES_LIST="gpu[001-016]"
export MASTER_PORT=29500

# æ—¥å¿—é…ç½®
export LOG_DIR=/shared/experiments/llama3_8b_$(date +%Y%m%d_%H%M%S)

# æäº¤è®­ç»ƒä»»åŠ¡
bash examples/run_slurm_pretrain_cli.sh
```

---

## ğŸ”§ é«˜çº§ç”¨æ³•

### ä¼ é€’é¢å¤–å‚æ•°

æ‰€æœ‰è„šæœ¬éƒ½æ”¯æŒä¼ é€’é¢å¤–å‚æ•°åˆ° `primus train` å‘½ä»¤ï¼š

```bash
# Direct mode
bash examples/run_pretrain_cli.sh --extra-param value

# Container mode
bash examples/run_local_pretrain_cli.sh --debug --dry-run

# Slurm mode
bash examples/run_slurm_pretrain_cli.sh --checkpoint-interval 100
```

### ç¯å¢ƒå˜é‡ä¼ é€’ï¼ˆContainer Modeï¼‰

`run_local_pretrain_cli.sh` æ”¯æŒä¼ é€’ç¯å¢ƒå˜é‡åˆ°å®¹å™¨ï¼š

```bash
# è„šæœ¬ä¸­å·²åŒ…å«çš„ç¯å¢ƒå˜é‡ç¤ºä¾‹ï¼š
# --env HSA_NO_SCRATCH_RECLAIM     # ä»ä¸»æœºä¼ é€’
# --env NVTE_CK_USES_BWD_V3        # ä»ä¸»æœºä¼ é€’
# --env GPU_MAX_HW_QUEUES          # ä»ä¸»æœºä¼ é€’
# --env GLOO_SOCKET_IFNAME         # ä»ä¸»æœºä¼ é€’

# åœ¨ä¸»æœºè®¾ç½®ç¯å¢ƒå˜é‡ï¼Œå®¹å™¨ä¼šè‡ªåŠ¨è·å–
export HSA_NO_SCRATCH_RECLAIM=1
export GPU_MAX_HW_QUEUES=2
bash examples/run_local_pretrain_cli.sh
```

---

## ğŸ“ å¸¸è§é—®é¢˜

### Q: å¦‚ä½•é€‰æ‹©ä½¿ç”¨å“ªä¸ªè„šæœ¬ï¼Ÿ

**A**:
- ğŸƒ **å¿«é€Ÿæµ‹è¯•**: ä½¿ç”¨ `run_pretrain_cli.sh`ï¼ˆç›´æ¥æ¨¡å¼ï¼‰
- ğŸ³ **ç¯å¢ƒéš”ç¦»**: ä½¿ç”¨ `run_local_pretrain_cli.sh`ï¼ˆå®¹å™¨æ¨¡å¼ï¼‰
- ğŸ–¥ï¸ **å¤šèŠ‚ç‚¹è®­ç»ƒ**: ä½¿ç”¨ `run_slurm_pretrain_cli.sh`ï¼ˆSlurm æ¨¡å¼ï¼‰

### Q: å®¹å™¨æ¨¡å¼çš„æ•°æ®è·¯å¾„å¦‚ä½•è®¾ç½®ï¼Ÿ

**A**: ä½¿ç”¨ `DATA_PATH` ç¯å¢ƒå˜é‡ï¼Œè¯¥è·¯å¾„ä¼šè‡ªåŠ¨æŒ‚è½½åˆ°å®¹å™¨å†…ï¼š

```bash
DATA_PATH=/mnt/shared/datasets bash examples/run_local_pretrain_cli.sh
```

### Q: Slurm æ¨¡å¼å¦‚ä½•æŸ¥çœ‹æ—¥å¿—ï¼Ÿ

**A**: æ—¥å¿—ä¼šä¿å­˜åˆ° `LOG_DIR/log_slurm_pretrain.txt`ï¼š

```bash
# å®æ—¶æŸ¥çœ‹æ—¥å¿—
tail -f ./output/log_slurm_pretrain.txt

# æˆ–æŒ‡å®šæ—¥å¿—ç›®å½•
LOG_DIR=/tmp/my_logs bash examples/run_slurm_pretrain_cli.sh
tail -f /tmp/my_logs/log_slurm_pretrain.txt
```

### Q: å¦‚ä½•éªŒè¯è„šæœ¬é…ç½®æ˜¯å¦æ­£ç¡®ï¼Ÿ

**A**: ä½¿ç”¨ `--dry-run` å‚æ•°ï¼ˆDirect å’Œ Container æ¨¡å¼æ”¯æŒï¼‰ï¼š

```bash
# éªŒè¯é…ç½®ä½†ä¸å®é™…æ‰§è¡Œ
bash examples/run_pretrain_cli.sh --dry-run
bash examples/run_local_pretrain_cli.sh --dry-run
```

---

## ğŸ“š å‚è€ƒèµ„æ–™

- [Primus CLI å®Œæ•´æ–‡æ¡£](../runner/README.md)
- [é…ç½®æ–‡ä»¶ç¤ºä¾‹](../examples/)
- [æ•…éšœæ’æŸ¥æŒ‡å—](../docs/troubleshooting.md)

---

## ğŸ¯ å¿«é€Ÿå‚è€ƒ

```bash
# ===== Direct Mode =====
EXP=config.yaml bash examples/run_pretrain_cli.sh

# ===== Container Mode (PyTorch) =====
bash examples/run_local_pretrain_cli.sh

# ===== Container Mode (MaxText) =====
BACKEND=MaxText bash examples/run_local_pretrain_cli.sh

# ===== Slurm Mode =====
NNODES=4 NODES_LIST="node[01-04]" bash examples/run_slurm_pretrain_cli.sh
```

---

**æ›´æ–°æ—¶é—´**: 2026-01-09
**ç‰ˆæœ¬**: v1.0
