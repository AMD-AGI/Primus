work_group: ${PRIMUS_TEAM:amd}
user_name: ${PRIMUS_USER:root}
exp_name: ${PRIMUS_EXP_NAME:deepseek_v2_16B-pretrain}
workspace: ./output

modules:
  pre_trainer:
    framework: maxtext
    config: pre_trainer.yaml

    # model to run
    model: deepseek_v2_16B.yaml
    overrides:
      run_name: "deepseek_v2_16b_training"
      base_output_directory: "./output"
      steps: 50
      log_period: 10
      profiler: ""

      # data
      dataset_type: "synthetic"
      hf_access_token: ${HF_TOKEN:""}

      # checkpoint
      enable_checkpointing: False
      async_checkpointing: False

      # inter-node parallelism strategy
      dcn_data_parallelism: -1
      dcn_fsdp_parallelism: 1
      dcn_pipeline_parallelism: 1
      dcn_tensor_parallelism: 1
      dcn_sequence_parallelism: 1

      # intra-node parallelism strategy
      ici_fsdp_parallelism: 1
      ici_data_parallelism: 1
      ici_expert_parallelism: -1
      ici_sequence_parallelism: 1
      ici_tensor_parallelism: 1
      ici_pipeline_parallelism: 1

      megablox: False
      capacity_factor: 1.25
      sparse_matmul: False
      sharding_tolerance: 0.05
      max_target_length: 4096
      per_device_batch_size: 8
      remat_policy: "minimal_flash"
