work_group: ${PRIMUS_TEAM:amd}
user_name: ${PRIMUS_USER:root}
exp_name: ${PRIMUS_EXP_NAME:llama3_70B-pretrain}
workspace: ./output

modules:
  pre_trainer:
    framework: torchtitan
    config: pre_trainer.yaml

    # model to run
    model: llama3.1_70B-fp8.yaml
    overrides:
      sink_level: null
      file_sink_level: DEBUG
      stderr_sink_level: INFO

      lr_scheduler:
        # lr scheduler warm up
        warmup_steps: 10

      metrics:
        log_freq: 1

      training:
        batch_size: 6
        compile: true
        steps: 10

      optimizer:
        lr: 1.5e-4

      activation_checkpoint:
        mode: full

      float8:
        enable_fsdp_float8_all_gather: true
        precompute_float8_dynamic_scale_for_fsdp: true
        filter_fqns: ["output"]

      primus_turbo:
        enable_primus_turbo : true
        use_turbo_attention: true
        enable_attention_float8 : false
        use_turbo_fp8_gemm: false  # 禁用Primus-Turbo FP8（与PyTorch FP8冲突）
