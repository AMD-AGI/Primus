
# logging
disable_tensorboard: true
disable_wandb: true
disable_mlflow: true
mlflow_run_name: null
mlflow_experiment_name: null
# When disable_mlflow=false, set these to true to upload traces/logs to MLflow.
# Default false so MLflow remains opt-in and disable_mlflow is respected.
mlflow_upload_traces: false          # Upload profiler trace files to MLflow
mlflow_upload_logs: false            # Upload training log files to MLflow

# TraceLens Report Generation & Upload
# ----------------------------------------------------------------------------
# Supported options: generate_tracelens_report, mlflow_upload_tracelens_report,
#   mlflow_tracelens_ranks, mlflow_tracelens_output_format, mlflow_tracelens_cleanup_after_upload
#
# generate_tracelens_report:          Generate TraceLens analysis reports locally
# mlflow_upload_tracelens_report:     Upload reports to MLflow (auto-enables generation)
#
# Usage patterns:
#   generate=false, upload=false  ->  No reports generated
#   generate=true,  upload=false  ->  Generate reports locally only
#   generate=false, upload=true   ->  Generate AND upload (auto-enabled)
#   generate=true,  upload=true   ->  Generate AND upload (explicit)
#
# To limit number of reports: use mlflow_tracelens_ranks (no separate max_reports option).
#   Default: [0, 8] = one rank per node (assumes 8 GPUs/node)
#   Use null for all ranks (e.g., null or [0, 1, 2] for explicit list)
# ----------------------------------------------------------------------------
generate_tracelens_report: false    # Generate TraceLens analysis reports locally (auto-enabled when upload=true)
mlflow_upload_tracelens_report: false # Upload TraceLens reports to MLflow (auto-enables generation, profiling, tensorboard)
mlflow_tracelens_ranks: [0, 8]       # List of ranks to analyze (null = all, e.g. [0, 1, 2])
# TraceLens report format: xlsx (default, single parse, fastest), csv, or all (xlsx+csv;
# parses each trace twice so ~2x processing time; use only when both formats are needed)
mlflow_tracelens_output_format: xlsx
mlflow_tracelens_cleanup_after_upload: false  # Keep local reports (true to cleanup and save disk space)
mlflow_tracelens_auto_install: true           # Auto-install TraceLens if missing (set false to disable)
disable_compile_dependencies: true
# NOTE:
# - If `use_rocm_mem_info = True`, ROCm memory information will be collected
#   with `rocm-smi` at every iteration.
# - If `use_rocm_mem_info = False`, memory information will only be collected
#   at the iterations specified in `use_rocm_mem_info_iters`.
use_rocm_mem_info: false
use_rocm_mem_info_iters: [1,2]

# MLflow performance metrics - comprehensive metrics for scaling tests
# When enabled, automatically enables throughput calculations and logs to MLflow:
#
#   1. Performance Metrics:
#      - perf/throughput_tflops_per_gpu: TFLOP/s per GPU
#      - perf/tps_tokens_per_sec_per_gpu: Tokens/sec per GPU
#      - perf/iteration_time_ms: Time per training step (ms)
#
#   2. Memory Metrics:
#      - perf/{rocm/hip}_current_mem_gb: Current GPU memory usage (GB)
#      - perf/{rocm/hip}_mem_utilization_pct: Memory utilization (% of total)
#
#   3. System Metrics:
#      - perf/gpu_utilization_pct_rank{N}: GPU utilization per rank (%)
#      - perf/gpu_utilization_pct_avg: Average GPU utilization across all ranks (%)
#
# Note: This flag implicitly enables log_throughput behavior for metric collection.
mlflow_upload_performance_metrics: false

# profiling
disable_profiler_activity_cpu: false
torch_profiler_record_shapes: true
torch_profiler_with_stack: true
torch_profiler_use_gzip: false

# continue/finetune
auto_continue_train: false
disable_last_saving: false

# fp8
no_fp8_weight_transpose_cache: false

# parallelism
decoder_pipeline_manual_split_list: null # int list

# MoE comm & comp Overlap
patch_moe_overlap: false

# perf
pp_warmup: false # set to true to decrease iter-1 time when using pp

# tool
dump_pp_data: false

# recompute
recompute_layer_ids: null #int listï¼Œid srange from 0 to (num_layers_per_pp_stage - 1)
