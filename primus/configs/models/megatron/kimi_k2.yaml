extends:
  - deepseek_v3_base.yaml

# https://huggingface.co/moonshotai/Kimi-K2-Instruct/blob/main/config.json
# 1039.77B total params, 27.03B active params

tokenizer_type: DeepSeekV3Tokenizer
tokenizer_model: moonshotai/Kimi-K2-Instruct

# model
num_layers: 61
hidden_size: 7168
ffn_hidden_size: 18432
num_attention_heads: 64

# mla
q_lora_rank: 1536
kv_lora_rank: 512
qk_head_dim: 128
qk_pos_emb_head_dim: 64
v_head_dim: 128
kv_channels: 128

# mtp
mtp_num_layers: 1
mtp_loss_scaling_factor: 0.1

# moe
moe_layer_freq: "([0]*3+[1]*58)"
num_experts: 384
moe_router_topk: 8
num_shared_experts: 1
moe_ffn_hidden_size: 2048
moe_shared_expert_intermediate_size: 2048

# device limited routing
expert_model_parallel_size: 8
moe_router_num_groups: 8
moe_router_group_topk: 4
moe_router_topk_scaling_factor: 2.5
