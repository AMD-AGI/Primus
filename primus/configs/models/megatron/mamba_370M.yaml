bases:
  - mamba_base.yaml

# Mamba 370M configuration

tokenizer_type: GPT2BPETokenizer
vocab_size: 50257

# Model size parameters
num_layers: 48
hidden_size: 1024
ffn_hidden_size: null

max_position_embeddings: 2048

