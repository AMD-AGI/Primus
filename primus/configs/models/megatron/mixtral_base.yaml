bases:
  - llama_base.yaml

init_method_std: 0.01
rotary_base: 1000000
qk_layernorm: false

group_query_attention: true
num_query_groups: 8

# moe parameters
num_experts: 8
moe_router_topk: 2
moe_router_load_balancing_type: aux_loss
moe_aux_loss_coeff: 1.0e-2
moe_grouped_gemm: true
moe_token_dispatcher_type: alltoall
