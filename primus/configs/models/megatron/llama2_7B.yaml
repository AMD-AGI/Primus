bases:
  - llama2_base.yaml

tokenizer_type: Llama2Tokenizer
tokenizer_model: meta-llama/Llama-2-7b-hf

group_query_attention: false

ffn_hidden_size: 11008
hidden_size: 4096
num_attention_heads: 32
num_layers: 32
