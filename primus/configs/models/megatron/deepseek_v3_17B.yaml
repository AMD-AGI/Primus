bases:
  - deepseek_v3_base.yaml

# 17B total params, 3B active params

tokenizer_type: DeepSeekV3Tokenizer
tokenizer_model: deepseek-ai/DeepSeek-V3

# model
num_layers: 28
hidden_size: 2048
ffn_hidden_size: 7168
num_attention_heads: 16
# mla
q_lora_rank: null
kv_lora_rank: 512
qk_head_dim: 128
qk_pos_emb_head_dim: 0
v_head_dim: 128
kv_channels: 128
# moe
moe_layer_freq: "([0]*2+[1]*26)"
num_experts: 96
moe_router_topk: 6
# num_shared_experts: 1
moe_ffn_hidden_size: 1024
moe_shared_expert_intermediate_size: 1024 # num_shared_experts * moe_ffn_hidden_size

# parallel and optimization
expert_model_parallel_size: 8
moe_router_num_groups: 8 # int
moe_router_group_topk: 3 # int
moe_aux_loss_coeff: 1.0e-4 # aux_loss_alpha
