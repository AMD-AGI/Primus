job:
  dump_folder: "./outputs"
  description: "Llama 3.1 8B training"

model:
  name: "llama3"
  flavor: "8B"
  hf_assets_path: "meta-llama/Llama-3.1-8B"
  converters:
    - primus_turbo
    - quantize.linear.float8
