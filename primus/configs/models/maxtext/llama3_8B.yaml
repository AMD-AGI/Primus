bases:
  - model_base.yaml

model_name: "llama3-8b"
tokenizer_path: "meta-llama/Meta-Llama-3-8B"
attention: "cudnn_flash_te"
use_iota_embed: True
