W1031 08:26:05.664000 138471 torch/distributed/run.py:803]
W1031 08:26:05.664000 138471 torch/distributed/run.py:803] *****************************************
W1031 08:26:05.664000 138471 torch/distributed/run.py:803] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
W1031 08:26:05.664000 138471 torch/distributed/run.py:803] *****************************************
[Primus CLI] HF_HOME already set: /shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/data/huggingface
[PrimusConfig] Detected unknown override keys: ['model']
[Primus] sys.path.insert: /shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/torchtitan
[[32m20251031 08:26:07[0m][[36mrank-1/8[0m][[33m[1mWARNING[0m] [33m[1m[PrimusPatch][AMP] nn.Embedding.__init__ patched for AMP/mixed precision alignment.[0m
[[32m20251031 08:26:07[0m][[36mrank-1/8[0m][[33m[1mWARNING[0m] [33m[1m[PrimusPatch][Dataset] Patched datasets.load_dataset successfully.[0m
[[32m20251031 08:26:07[0m][[36mrank-1/8[0m][[33m[1mWARNING[0m] [33m[1m[PrimusPatch][DCP] Installed fallback for missing torch.distributed.checkpoint._consolidate_hf_safetensors.consolidate_safetensors_files_on_every_rank, HuggingFace safetensors export will be disabled.[0m
[[32m20251031 08:26:08[0m][[36mrank-1/8[0m][[33m[1mWARNING[0m] [33m[1m[PrimusPatch][Pipe] Installed fallback: ScheduleDualPipeV -> Schedule1F1B[0m
[[32m20251031 08:26:08[0m][[36mrank-1/8[0m][[33m[1mWARNING[0m] [33m[1m[PrimusPatch][FlexAttn] AuxOutput not found. This torch build predates the new debug/profiling return type. Injecting a lightweight stub so Titan model imports can succeed.[0m
[[32m20251031 08:26:08[0m][[36mrank-1/8[0m][[33m[1mWARNING[0m] [33m[1m[PrimusPatch][FlexAttn] Injected fallback AuxOutput stub (Titan does not rely on this).[0m
[[32m20251031 08:26:08[0m][[36mrank-1/8[0m][[33m[1mWARNING[0m] [33m[1m[PrimusPatch][Checkpoint] checkpoint_wrapper patched successfully[0m
[[32m20251031 08:26:08[0m][[36mrank-1/8[0m][[33m[1mWARNING[0m] [33m[1m[PrimusPatch][ModelOverride] Applying model_overrides: {'model': {'n_layers': 4}}[0m
[[32m20251031 08:26:08[0m][[36mrank-1/8[0m][[33m[1mWARNING[0m] [33m[1m[PrimusPatch][ModelOverride] Applying overrides: {'model.n_layers': 4}[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[33m[1mWARNING[0m] [33m[1m[PrimusPatch][ModelOverride] get_train_spec for 'llama3' successfully monkey patched (flavor=70B).[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mMokey patch torchtitan logger...[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mLoaded and merged custom JobConfig from primus.backends.torchtitan.primus_turbo_extensions.config_extension[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1m========== TorchTitan Config ==========[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments activation_checkpoint.early_stop.................................. False[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments activation_checkpoint.mode........................................ full[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments activation_checkpoint.per_op_sac_force_recompute_mm_shapes_by_fqns ['moe.router.gate'][0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments activation_checkpoint.selective_ac_option......................... 2[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments checkpoint.async_mode............................................. disabled[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments checkpoint.create_seed_checkpoint................................. False[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments checkpoint.enable................................................. False[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments checkpoint.enable_first_step_checkpoint........................... False[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments checkpoint.exclude_from_loading................................... [][0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments checkpoint.export_dtype........................................... float32[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments checkpoint.folder................................................. checkpoint[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments checkpoint.initial_load_in_hf..................................... False[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments checkpoint.initial_load_model_only................................ True[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments checkpoint.initial_load_path...................................... None[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments checkpoint.interval............................................... 500[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments checkpoint.keep_latest_k.......................................... 10[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments checkpoint.last_save_in_hf........................................ False[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments checkpoint.last_save_model_only................................... True[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments checkpoint.load_step.............................................. -1[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments comm.init_timeout_seconds......................................... 300[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments comm.save_traces_folder........................................... comm_traces[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments comm.trace_buf_size............................................... 20000[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments comm.train_timeout_seconds........................................ 100[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments compile.components................................................ ['model', 'loss'][0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments compile.enable.................................................... True[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments experimental.custom_args_module................................... primus.backends.torchtitan.primus_turbo_extensions.config_extension[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments experimental.custom_import........................................ [0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments fault_tolerance.enable............................................ False[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments fault_tolerance.group_size........................................ 0[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments fault_tolerance.min_replica_size.................................. 1[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments fault_tolerance.process_group..................................... gloo[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments fault_tolerance.process_group_timeout_ms.......................... 10000[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments fault_tolerance.replica_id........................................ 0[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments fault_tolerance.semi_sync_method.................................. None[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments float8.emulate.................................................... False[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments float8.enable_fsdp_float8_all_gather.............................. True[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments float8.filter_fqns................................................ ['output'][0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments float8.moe_fqns_prototype......................................... [][0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments float8.precompute_float8_dynamic_scale_for_fsdp................... True[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments float8.recipe_name................................................ None[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments job.config_file................................................... None[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments job.description................................................... Llama 3.1 70B training[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments job.dump_folder................................................... ./outputs[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments job.print_args.................................................... False[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments lr_scheduler.decay_ratio.......................................... None[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments lr_scheduler.decay_type........................................... linear[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments lr_scheduler.min_lr_factor........................................ 0.0[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments lr_scheduler.warmup_steps......................................... 10[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments memory_estimation.disable_fake_mode............................... False[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments memory_estimation.enable.......................................... False[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments metrics.disable_color_printing.................................... False[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments metrics.enable_tensorboard........................................ False[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments metrics.enable_wandb.............................................. False[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments metrics.log_freq.................................................. 1[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments metrics.save_for_all_ranks........................................ False[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments metrics.save_tb_folder............................................ tb[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments model.converters.................................................. ['float8'][0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments model.flavor...................................................... 70B[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments model.hf_assets_path.............................................. /shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/data/torchtitan/Llama-3.1-8B[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments model.name........................................................ llama3[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments model.print_after_conversion...................................... False[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments model.tokenizer_path.............................................. None[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments mx.filter_fqns.................................................... ['output'][0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments mx.moe_fqns_prototype............................................. [][0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments mx.mxfp8_dim1_cast_kernel_choice.................................. triton[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments mx.recipe_name.................................................... mxfp8_cublas[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments optimizer.beta1................................................... 0.9[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments optimizer.beta2................................................... 0.95[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments optimizer.early_step_in_backward.................................. False[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments optimizer.eps..................................................... 1e-08[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments optimizer.implementation.......................................... fused[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments optimizer.lr...................................................... 0.00015[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments optimizer.name.................................................... AdamW[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments optimizer.weight_decay............................................ 0.1[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.context_parallel_degree............................... 1[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.context_parallel_rotate_method........................ allgather[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.data_parallel_replicate_degree........................ 1[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.data_parallel_shard_degree............................ -1[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.disable_loss_parallel................................. False[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.enable_async_tensor_parallel.......................... False[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.enable_compiled_autograd.............................. False[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.expert_parallel_degree................................ 1[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.expert_tensor_parallel_degree......................... 1[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.fsdp_reshard_after_forward............................ default[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.module_fqns_per_model_part............................ None[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.pipeline_parallel_degree.............................. 1[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.pipeline_parallel_first_stage_less_layers............. 1[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.pipeline_parallel_last_stage_less_layers.............. 1[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.pipeline_parallel_layers_per_stage.................... None[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.pipeline_parallel_microbatch_size..................... 1[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.pipeline_parallel_schedule............................ 1F1B[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.pipeline_parallel_schedule_csv........................ [0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.pipeline_parallel_split_points........................ [][0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.tensor_parallel_degree................................ 1[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments primus_turbo.enable_attention_float8.............................. False[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments primus_turbo.enable_embedding_autocast............................ True[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments primus_turbo.enable_primus_turbo.................................. True[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments primus_turbo.use_turbo_async_tp................................... True[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments primus_turbo.use_turbo_attention.................................. True[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments primus_turbo.use_turbo_mx_linear.................................. True[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments profiling.enable_memory_snapshot.................................. False[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments profiling.enable_profiling........................................ False[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments profiling.profile_freq............................................ 10[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments profiling.save_memory_snapshot_folder............................. memory_snapshot[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments profiling.save_traces_folder...................................... profile_traces[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments training.dataset.................................................. c4[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments training.dataset_path............................................. None[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments training.deterministic............................................ False[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments training.enable_cpu_offload....................................... False[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments training.gc_debug................................................. False[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments training.gc_freq.................................................. 50[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments training.global_batch_size........................................ -1[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments training.local_batch_size......................................... 3[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments training.max_norm................................................. 1.0[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments training.mixed_precision_param.................................... bfloat16[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments training.mixed_precision_reduce................................... float32[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments training.seed..................................................... None[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments training.seq_len.................................................. 2048[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments training.steps.................................................... 3[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments validation.dataset................................................ c4_validation[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments validation.dataset_path........................................... None[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments validation.enable................................................. False[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments validation.freq................................................... 10[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments validation.local_batch_size....................................... 8[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments validation.seq_len................................................ 2048[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments validation.steps.................................................. -1[0m
[[32m20251031 08:26:10[0m][[36mrank-1/8[0m][[33m[1mWARNING[0m] [33m[1mTorchtitanPretrainTrainer: Patch Turbo Attention[0m
[[32m20251031 08:26:11[0m][[36mrank-1/8[0m][[33m[1mWARNING[0m] [33m[1mTorchtitanPretrainTrainer: Patch Turbo MXLinear[0m
[[32m20251031 08:26:11[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mEnable primus turbo extension...[0m
[[32m20251031 08:26:11[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mStarting job: Llama 3.1 70B training[0m
[[32m20251031 08:26:11[0m][[36mrank-1/8[0m][[33m[1mWARNING[0m] [33m[1mENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config[0m
[[32m20251031 08:26:11[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mBuilding 1-D device mesh with ['dp_shard'], [8][0m
[[32m20251031 08:26:11[0m][[36mrank-1/8[0m][[1mINFO [0m] [1m[GC] Initial GC collection 0.00 seconds[0m
[[32m20251031 08:26:14[0m][[36mrank-1/8[0m][[33m[1mWARNING[0m] [33m[1m[PrimusPatch][ModelOverride] Successfully patched model_args['70B'] for 'llama3' with {'model.n_layers': 4}. Diff(beforeâ†’after): {'_enforced': 'This field is used to enforce all fields have defaults.', 'dim': 8192, 'n_layers': 80, 'n_heads': 64, 'n_kv_heads': 8, 'vocab_size': 128256, 'multiple_of': 4096, 'ffn_dim_multiplier': 1.3, 'norm_eps': 1e-05, 'rope_theta': 500000, 'max_seq_len': 131072, 'depth_init': True, 'use_flex_attn': False, 'attn_mask_type': 'causal', 'eos_id': 0} â†’ {'_enforced': 'This field is used to enforce all fields have defaults.', 'dim': 8192, 'n_layers': 4, 'n_heads': 64, 'n_kv_heads': 8, 'vocab_size': 128256, 'multiple_of': 4096, 'ffn_dim_multiplier': 1.3, 'norm_eps': 1e-05, 'rope_theta': 500000, 'max_seq_len': 131072, 'depth_init': True, 'use_flex_attn': False, 'attn_mask_type': 'causal', 'eos_id': 0}[0m
[[32m20251031 08:26:14[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mLoading tokenizer from tokenizer.json[0m
[[32m20251031 08:26:14[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mPreparing c4 dataset from allenai/c4[0m
[[32m20251031 08:26:14[0m][[36mrank-1/8[0m][[33m[1mWARNING[0m] [33m[1m[PrimusPatch][MockDataset] load_dataset('allenai/c4') is mocked.[0m
[[32m20251031 08:26:14[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mBuilding llama3 70B with TransformerModelArgs(_enforced='This field is used to enforce all fields have defaults.', dim=8192, n_layers=4, n_heads=64, n_kv_heads=8, vocab_size=128256, multiple_of=4096, ffn_dim_multiplier=1.3, norm_eps=1e-05, rope_theta=500000, max_seq_len=2048, depth_init=True, use_flex_attn=False, attn_mask_type='causal', eos_id=0)[0m
/opt/venv/lib/python3.10/site-packages/torchao/utils.py:408: UserWarning: TORCH_VERSION_AT_LEAST_2_5 is deprecated and will be removed in torchao 0.14.0
  warnings.warn(self.msg)
[[32m20251031 08:26:15[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mFloat8 tensorwise scaled training active[0m
[[32m20251031 08:26:15[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mSwapped to Float8Linear layers with enable_fsdp_float8_all_gather=True[0m
[[32m20251031 08:26:15[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mCUDA capacity: AMD Instinct MI300X with 191.98GiB memory[0m
[[32m20251031 08:26:15[0m][[36mrank-1/8[0m][[1mINFO [0m] [1m[34mModel llama3 70B [31msize: 5,523,972,096 total parameters[39m[0m
[[32m20251031 08:26:15[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mCompiling the loss function with torch.compile[0m
[[32m20251031 08:26:15[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mApplied full activation checkpointing to the model[0m
[[32m20251031 08:26:15[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mCompiling each TransformerBlock with torch.compile[0m
[[32m20251031 08:26:15[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mApplied FSDP to the model[0m
[[32m20251031 08:26:15[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mPeak FLOPS used for computing MFU: 1.300e+15[0m
[[32m20251031 08:26:15[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mCUDA memory usage for model: 2.59GiB(1.35%)[0m
[[32m20251031 08:26:15[0m][[36mrank-1/8[0m][[33m[1mWARNING[0m] [33m[1mWarmup steps (10) exceed total training steps (3). Adjusting warmup steps to 3.[0m
[[32m20251031 08:26:15[0m][[36mrank-1/8[0m][[33m[1mWARNING[0m] [33m[1mmodel.safetensors.index.json not found at hf_assets_path: /shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/data/torchtitan/Llama-3.1-8B/model.safetensors.index.json.                     Defaulting to saving a single safetensors file if checkpoint is saved in HF format[0m
[[32m20251031 08:26:15[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mMixed precision training is handled by fully_shard[0m
[[32m20251031 08:26:15[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mTrainer is initialized with local batch size 3, global batch size 24, gradient accumulation steps 1, sequence length 2048, total steps 3 (warmup 10)[0m
[[32m20251031 08:26:15[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mTraining starts at step 1[0m
/opt/venv/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py:1652: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
  torch._dynamo.utils.warn_once(msg)
/opt/venv/lib/python3.10/site-packages/torch/_inductor/lowering.py:1937: UserWarning: Torchinductor does not support code generation for complex operators. Performance may be worse than eager.
  warnings.warn(
[aiter] type hints mismatch, override to --> fmha_v3_fwd(q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, dropout_p: float, softmax_scale: float, is_causal: bool, window_size_left: int, window_size_right: int, return_softmax_lse: bool, return_dropout_randval: bool, out: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> list[torch.Tensor]
[[32m20251031 08:26:18[0m][[36mrank-1/8[0m][[33m[1mWARNING[0m] [33m[1mtype hints mismatch, override to --> fmha_v3_fwd(q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, dropout_p: float, softmax_scale: float, is_causal: bool, window_size_left: int, window_size_right: int, return_softmax_lse: bool, return_dropout_randval: bool, out: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> list[torch.Tensor][0m
[aiter] type hints mismatch, override to --> fmha_v3_bwd(dout: torch.Tensor, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, out: torch.Tensor, softmax_lse: torch.Tensor, dropout_p: float, softmax_scale: float, is_causal: bool, window_size_left: int, window_size_right: int, deterministic: bool, is_v3_atomic_fp32: bool, how_v3_bf16_cvt: int, dq: Optional[torch.Tensor] = None, dk: Optional[torch.Tensor] = None, dv: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, rng_state: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> list[torch.Tensor]
[[32m20251031 08:26:21[0m][[36mrank-1/8[0m][[33m[1mWARNING[0m] [33m[1mtype hints mismatch, override to --> fmha_v3_bwd(dout: torch.Tensor, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, out: torch.Tensor, softmax_lse: torch.Tensor, dropout_p: float, softmax_scale: float, is_causal: bool, window_size_left: int, window_size_right: int, deterministic: bool, is_v3_atomic_fp32: bool, how_v3_bf16_cvt: int, dq: Optional[torch.Tensor] = None, dk: Optional[torch.Tensor] = None, dv: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, rng_state: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> list[torch.Tensor][0m
[[32m20251031 08:26:22[0m][[36mrank-1/8[0m][[1mINFO [0m] [1m[31mstep:  1  [32mloss: 12.2949  [38;2;180;60;0mgrad_norm: 10.4764  [38;2;54;234;195mmemory: 23.88GiB(12.44%)  [34mtps: 897  [36mtflops: 24.81  [35mmfu: 1.91%[39m[0m
[[32m20251031 08:26:22[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mSynchronizing and adjusting timeout for all ProcessGroups to 0:01:40[0m
[[32m20251031 08:26:22[0m][[36mrank-1/8[0m][[1mINFO [0m] [1m[31mstep:  2  [32mloss: 10.9719  [38;2;180;60;0mgrad_norm: 59.0567  [38;2;54;234;195mmemory: 25.84GiB(13.46%)  [34mtps: 16,601  [36mtflops: 458.95  [35mmfu: 35.30%[39m[0m
[[32m20251031 08:26:22[0m][[36mrank-1/8[0m][[1mINFO [0m] [1m[31mstep:  3  [32mloss:  9.6786  [38;2;180;60;0mgrad_norm:  9.9907  [38;2;54;234;195mmemory: 25.84GiB(13.46%)  [34mtps: 16,761  [36mtflops: 463.36  [35mmfu: 35.64%[39m[0m
[[32m20251031 08:26:22[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mTraining completed[0m
