W1030 07:30:41.274000 102687 torch/distributed/run.py:803]
W1030 07:30:41.274000 102687 torch/distributed/run.py:803] *****************************************
W1030 07:30:41.274000 102687 torch/distributed/run.py:803] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
W1030 07:30:41.274000 102687 torch/distributed/run.py:803] *****************************************
[Primus CLI] HF_HOME already set: /shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/data/huggingface
[Primus CLI] HF_HOME already set: /shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/data/huggingface
[Primus CLI] HF_HOME already set: /shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/data/huggingface
[Primus CLI] HF_HOME already set: /shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/data/huggingface
[Primus CLI] HF_HOME already set: /shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/data/huggingface
[Primus CLI] HF_HOME already set: /shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/data/huggingface
[Primus CLI] HF_HOME already set: /shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/data/huggingface
[Primus CLI] HF_HOME already set: /shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/data/huggingface
[Primus] sys.path.insert: /shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM
[Primus] sys.path.insert: /shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM
[Primus] sys.path.insert: /shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM
[Primus] sys.path.insert: /shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM
[Primus] sys.path.insert: /shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM
[Primus] sys.path.insert: /shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM
[Primus] sys.path.insert: /shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM
[Primus] sys.path.insert: /shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM
[WARNING  | transformer_engine.pytorch.dot_product_attention.utils]: Supported flash-attn versions are >= 2.1.1, <= 2.8.0.post2. Found flash-attn 2.8.3.
[WARNING  | transformer_engine.pytorch.dot_product_attention.utils]: Supported flash-attn versions are >= 2.1.1, <= 2.8.0.post2. Found flash-attn 2.8.3.
[WARNING  | transformer_engine.pytorch.dot_product_attention.utils]: Supported flash-attn versions are >= 2.1.1, <= 2.8.0.post2. Found flash-attn 2.8.3.
[WARNING  | transformer_engine.pytorch.dot_product_attention.utils]: Supported flash-attn versions are >= 2.1.1, <= 2.8.0.post2. Found flash-attn 2.8.3.
[WARNING  | transformer_engine.pytorch.dot_product_attention.utils]: Supported flash-attn versions are >= 2.1.1, <= 2.8.0.post2. Found flash-attn 2.8.3.
[WARNING  | transformer_engine.pytorch.dot_product_attention.utils]: Supported flash-attn versions are >= 2.1.1, <= 2.8.0.post2. Found flash-attn 2.8.3.
[WARNING  | transformer_engine.pytorch.dot_product_attention.utils]: Supported flash-attn versions are >= 2.1.1, <= 2.8.0.post2. Found flash-attn 2.8.3.
[WARNING  | transformer_engine.pytorch.dot_product_attention.utils]: Supported flash-attn versions are >= 2.1.1, <= 2.8.0.post2. Found flash-attn 2.8.3.
[92mSuccessfully preprocessed all matching files.[0m
/shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM/megatron/core/inference/unified_memory.py:83: UserWarning: Failed to create unified memory mempool.
  warnings.warn("Failed to create unified memory mempool.")
[92mSuccessfully preprocessed all matching files.[0m
/shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM/megatron/core/inference/unified_memory.py:83: UserWarning: Failed to create unified memory mempool.
  warnings.warn("Failed to create unified memory mempool.")
/shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM/megatron/core/inference/unified_memory.py:83: UserWarning: Failed to create unified memory mempool.
  warnings.warn("Failed to create unified memory mempool.")
/shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM/megatron/core/inference/unified_memory.py:83: UserWarning: Failed to create unified memory mempool.
  warnings.warn("Failed to create unified memory mempool.")
/shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM/megatron/core/inference/unified_memory.py:83: UserWarning: Failed to create unified memory mempool.
  warnings.warn("Failed to create unified memory mempool.")
/shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM/megatron/core/inference/unified_memory.py:83: UserWarning: Failed to create unified memory mempool.
  warnings.warn("Failed to create unified memory mempool.")
/shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM/megatron/core/inference/unified_memory.py:83: UserWarning: Failed to create unified memory mempool.
  warnings.warn("Failed to create unified memory mempool.")
/shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM/megatron/core/inference/unified_memory.py:83: UserWarning: Failed to create unified memory mempool.
  warnings.warn("Failed to create unified memory mempool.")
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM/megatron/core/energy_monitor.py:9: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  from pynvml import (
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM/megatron/core/energy_monitor.py:9: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  from pynvml import (
/shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM/megatron/core/energy_monitor.py:9: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  from pynvml import (
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM/megatron/core/energy_monitor.py:9: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  from pynvml import (
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM/megatron/core/energy_monitor.py:9: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  from pynvml import (
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM/megatron/core/energy_monitor.py:9: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  from pynvml import (
/shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM/megatron/core/energy_monitor.py:9: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  from pynvml import (
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM/megatron/core/energy_monitor.py:9: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  from pynvml import (
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
/opt/venv/lib/python3.10/site-packages/torchao/utils.py:408: UserWarning: TORCH_VERSION_AT_LEAST_2_5 is deprecated and will be removed in torchao 0.14.0
  warnings.warn(self.msg)
/opt/venv/lib/python3.10/site-packages/torchao/utils.py:408: UserWarning: TORCH_VERSION_AT_LEAST_2_5 is deprecated and will be removed in torchao 0.14.0
  warnings.warn(self.msg)
/opt/venv/lib/python3.10/site-packages/torchao/utils.py:408: UserWarning: TORCH_VERSION_AT_LEAST_2_5 is deprecated and will be removed in torchao 0.14.0
  warnings.warn(self.msg)
/opt/venv/lib/python3.10/site-packages/torchao/utils.py:408: UserWarning: TORCH_VERSION_AT_LEAST_2_5 is deprecated and will be removed in torchao 0.14.0
  warnings.warn(self.msg)
/opt/venv/lib/python3.10/site-packages/torchao/utils.py:408: UserWarning: TORCH_VERSION_AT_LEAST_2_5 is deprecated and will be removed in torchao 0.14.0
  warnings.warn(self.msg)
/opt/venv/lib/python3.10/site-packages/torchao/utils.py:408: UserWarning: TORCH_VERSION_AT_LEAST_2_5 is deprecated and will be removed in torchao 0.14.0
  warnings.warn(self.msg)
/opt/venv/lib/python3.10/site-packages/torchao/utils.py:408: UserWarning: TORCH_VERSION_AT_LEAST_2_5 is deprecated and will be removed in torchao 0.14.0
  warnings.warn(self.msg)
/opt/venv/lib/python3.10/site-packages/torchao/utils.py:408: UserWarning: TORCH_VERSION_AT_LEAST_2_5 is deprecated and will be removed in torchao 0.14.0
  warnings.warn(self.msg)
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[33m[1mWARNING[0m] [33m[1m[trainer.py:438]: MegatronTrainer: monkey patch TopKRouter...[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[33m[1mWARNING[0m] [33m[1m[trainer.py:308]: MegatronTrainer: monkey patch get_extra_te_kwargs...[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[33m[1mWARNING[0m] [33m[1m[trainer.py:541]: MegatronTrainer: Patching FileSystemWriterAsync...[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[33m[1mWARNING[0m] [33m[1m[trainer.py:553]: MegatronTrainer: Patch FileSystemWriterAsync successfully.[0m
[[32m20251030 07:30:51[0m][[36mrank-7/8[0m][[34m[1mDEBUG[0m] [34m[1m[-----global_vars.py:236] : WARNING: one_logger package is required to enable e2e metrics tracking. please go to https://confluence.nvidia.com/display/MLWFO/Package+Repositories for details to install it[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:647] : -run update_primus_config...[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:755] : -rank:              0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:756] : -local_rank:        0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:757] : -world_size:        8[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:774] : -save:              /shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/output/amd/root/tests/trainer/test_megatron_trainer.yaml/checkpoints[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:781] : -auto_continue_train:False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:817] : -disable_tensorboard:True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:818] :   -tensorboard_dir: None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[---------trainer.py:834] : args.wandb_project is disabled, as args.disable_wandb=True.[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:835] : -disable_wandb:     True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:841] :   -wandb_project:   None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:842] :   -wandb_exp_name:  None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:843] :   -wandb_save_dir:  None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:844] :   -wandb_entity:    None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:847] : -disable_mlflow:    True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:861] :   -mlflow_run_name: None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:862] :   -mlflow_experiment_name:None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[-----import_utils.py:30] : [Primus][MegatronCompat] Loaded model_provider from model_provider[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[-----import_utils.py:30] : [Primus][MegatronCompat] Loaded gpt_builder from gpt_builders[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:655] : -run initialize_megatron...[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[--------trainer.py:1089] : -load:              None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[--------trainer.py:1090] : -use_checkpoint_args:False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-------arguments.py:416] : using world size: 8, data-parallel size: 2, context-parallel size: 1, hierarchical context-parallel sizes: None, tensor-model-parallel size: 1, pipeline-model-parallel size: 4[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-------arguments.py:598] : Number of virtual stages per pipeline stage: 2[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-------arguments.py:722] : accumulate and all-reduce gradients in fp32 for bfloat16 data type.[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-------arguments.py:733] : using torch.bfloat16 for parameters ...[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1191] : ------------------------ arguments ------------------------[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   account_for_embedding_in_pipeline_split ......... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   account_for_loss_in_pipeline_split .............. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   accumulate_allreduce_grads_in_fp32 .............. True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   adam_beta1 ...................................... 0.9[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   adam_beta2 ...................................... 0.95[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   adam_eps ........................................ 1e-08[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   add_bias_linear ................................. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   add_position_embedding .......................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   add_qkv_bias .................................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   adlr_autoresume ................................. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   adlr_autoresume_interval ........................ 1000[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   align_grad_reduce ............................... True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   align_param_gather .............................. True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   allow_padding_num_layers ........................ True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   app_tag_run_name ................................ None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   app_tag_run_version ............................. 0.0.0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   apply_layernorm_1p .............................. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   apply_query_key_layer_scaling ................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   apply_residual_connection_post_layernorm ........ False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   apply_rope_fusion ............................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   async_save ...................................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   async_tensor_model_parallel_allreduce ........... True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   attention_backend ............................... auto[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   attention_dropout ............................... 0.0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   attention_softmax_in_fp32 ....................... True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   attn_logit_softcapping .......................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   auto_continue_train ............................. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   auto_detect_ckpt_format ......................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   auto_offload_time ............................... True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   barrier_with_L1_time ............................ True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   bert_binary_head ................................ True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   bert_embedder_type .............................. megatron[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   bert_load ....................................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   bf16 ............................................ True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   bias_dropout_fusion ............................. True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   bias_gelu_fusion ................................ False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   bias_swiglu_fusion .............................. True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   biencoder_projection_dim ........................ 0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   biencoder_shared_query_context_model ............ False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   block_data_path ................................. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   calc_ft_timeouts ................................ False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   calculate_per_token_loss ........................ False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   check_for_large_grads ........................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   check_for_nan_in_loss_and_grad .................. True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   check_for_spiky_loss ............................ False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   check_weight_hash_across_dp_replicas_interval ... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   ckpt_assume_constant_structure .................. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   ckpt_convert_format ............................. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   ckpt_convert_save ............................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   ckpt_convert_update_legacy_dist_opt_format ...... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   ckpt_format ..................................... torch[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   ckpt_fully_parallel_load ........................ False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   ckpt_fully_parallel_save ........................ True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   ckpt_fully_parallel_save_deprecated ............. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   ckpt_step ....................................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   classes_fraction ................................ 1.0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   clip_grad ....................................... 1.0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   clone_scatter_output_in_embedding ............... True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   config_logger_dir ............................... [0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   consumed_train_samples .......................... 0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   consumed_valid_samples .......................... 0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   context_parallel_size ........................... 1[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   cp_comm_type .................................... p2p[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   cpu_offload ..................................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   create_attention_mask_in_dataloader ............. True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   cross_entropy_fusion_impl ....................... native[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   cross_entropy_loss_fusion ....................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   cuda_graph_scope ................................ full[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   cuda_graph_warmup_steps ......................... 3[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   data_args_path .................................. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   data_cache_path ................................. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   data_parallel_random_init ....................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   data_parallel_sharding_strategy ................. no_shard[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   data_parallel_size .............................. 2[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   data_path ....................................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   data_per_class_fraction ......................... 1.0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   data_sharding ................................... True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   dataloader_type ................................. cyclic[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   ddp_average_in_collective ....................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   ddp_bucket_size ................................. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   ddp_num_buckets ................................. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   ddp_pad_buckets_for_high_nccl_busbw ............. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   debug_scheduler_table ........................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   decoder_first_pipeline_num_layers ............... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   decoder_last_pipeline_num_layers ................ None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   decoder_num_layers .............................. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   decoder_pipeline_manual_split_list .............. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   decoder_seq_length .............................. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   decoupled_lr .................................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   decoupled_min_lr ................................ None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   decrease_batch_size_if_needed ................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   defer_embedding_wgrad_compute ................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   delay_wgrad_compute ............................. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   deprecated_use_mcore_models ..................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   deterministic_mode .............................. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   dino_bottleneck_size ............................ 256[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   dino_freeze_last_layer .......................... 1[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   dino_head_hidden_size ........................... 2048[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   dino_local_crops_number ......................... 10[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   dino_local_img_size ............................. 96[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   dino_norm_last_layer ............................ False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   dino_teacher_temp ............................... 0.07[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   dino_warmup_teacher_temp ........................ 0.04[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   dino_warmup_teacher_temp_epochs ................. 30[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   disable_compile_dependencies .................... True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   disable_last_saving ............................. True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   disable_mamba_mem_eff_path ...................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   disable_mlflow .................................. True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   disable_primus_topk_router ...................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   disable_profiler_activity_cpu ................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   disable_straggler_on_startup .................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   disable_tensorboard ............................. True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   disable_wandb ................................... True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   dist_ckpt_format_deprecated ..................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   dist_ckpt_strictness ............................ assume_ok_unexpected[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   distribute_saved_activations .................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   distributed_backend ............................. nccl[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   distributed_timeout_minutes ..................... 60[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   dump_pp_data .................................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   embedding_path .................................. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   empty_unused_memory_level ....................... 0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   enable_1f1b_v ................................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   enable_cuda_graph ............................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   enable_exactly_numeric_match .................... True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   enable_experimental ............................. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   enable_ft_package ............................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   enable_gloo_process_groups ...................... True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   enable_one_logger ............................... True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   enable_optimizer_post_validation ................ False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   enable_primus_turbo ............................. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   enable_turbo_attention_float8 ................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   enable_zb_runtime ............................... True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   enable_zero_bubble .............................. True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   encoder_num_layers .............................. 8[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   encoder_pipeline_model_parallel_size ............ 0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   encoder_seq_length .............................. 4096[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   encoder_tensor_model_parallel_size .............. 0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   end_weight_decay ................................ 0.1[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   eod_mask_loss ................................... True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   error_injection_rate ............................ 0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   error_injection_type ............................ transient_error[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   eval_interval ................................... 1000[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   eval_iters ...................................... 0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   evidence_data_path .............................. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   exit_duration_in_mins ........................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   exit_interval ................................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   exit_on_missing_checkpoint ...................... True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   exit_signal_handler ............................. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   exp_avg_dtype ................................... torch.float32[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   exp_avg_sq_dtype ................................ torch.float32[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   expert_model_parallel_size ...................... 1[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   expert_tensor_parallel_size ..................... 1[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   external_cuda_graph ............................. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   ffn_hidden_size ................................. 10944[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   file_sink_level ................................. DEBUG[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   final_logit_softcapping ......................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   finetune ........................................ False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   first_last_layers_bf16 .......................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   flash_decode .................................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   fp16 ............................................ False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   fp16_lm_cross_entropy ........................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   fp32_residual_connection ........................ False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   fp4 ............................................. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   fp4_param ....................................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   fp4_recipe ...................................... nvfp4[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   fp8 ............................................. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   fp8_amax_compute_algo ........................... max[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   fp8_amax_history_len ............................ 1024[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   fp8_interval .................................... 1[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   fp8_margin ...................................... 0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   fp8_param_gather ................................ False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   fp8_recipe ...................................... delayed[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   fp8_wgrad ....................................... True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   framework ....................................... megatron[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   full_validation ................................. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   fused_padded_mla_attention ...................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   global_batch_size ............................... 16[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   grad_reduce_in_bf16 ............................. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   gradient_accumulation_fusion .................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   gradient_reduce_div_fusion ...................... True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   group_query_attention ........................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   grouped_gemm_backend ............................ turbo-gg[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   grpo_clamp_eps_lower ............................ 0.01[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   grpo_clamp_eps_upper ............................ 0.01[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   grpo_default_temperature ........................ 1.0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   grpo_default_top_p .............................. 0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   grpo_entropy_term_weight ........................ 0.0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   grpo_filter_groups_with_same_reward ............. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   grpo_group_size ................................. 2[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   grpo_iterations ................................. 2[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   grpo_kl_beta .................................... 0.001[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   grpo_prompts_per_step ........................... 32[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   head_lr_mult .................................... 1.0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   heterogeneous_layers_config_encoded_json ........ None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   heterogeneous_layers_config_path ................ None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   hidden_dropout .................................. 0.0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   hidden_size ..................................... 2048[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   hierarchical_context_parallel_sizes ............. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   high_priority_stream_groups ..................... [][0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   hybrid_attention_ratio .......................... 0.0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   hybrid_mlp_ratio ................................ 0.0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   hybrid_override_pattern ......................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   hysteresis ...................................... 2[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   ict_head_size ................................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   ict_load ........................................ None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   img_h ........................................... 224[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   img_w ........................................... 224[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   indexer_batch_size .............................. 128[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   indexer_log_interval ............................ 1000[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   inference_batch_times_seqlen_threshold .......... -1[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   inference_dynamic_batching ...................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   inference_dynamic_batching_buffer_guaranteed_fraction  0.2[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   inference_dynamic_batching_buffer_overflow_factor  None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   inference_dynamic_batching_buffer_size_gb ....... 40.0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   inference_dynamic_batching_max_requests_override  None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   inference_dynamic_batching_max_tokens_override .. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   inference_max_requests .......................... 8[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   inference_max_seq_length ........................ 2560[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   inference_rng_tracker ........................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   init_method_std ................................. 0.008[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   init_method_xavier_uniform ...................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   init_model_with_meta_device ..................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   initial_loss_scale .............................. 4294967296[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   inprocess_restart ............................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   interleave_group_size ........................... 0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   is_hybrid_model ................................. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   iter_per_epoch .................................. 1250[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   iterations_to_skip .............................. [][0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   keep_fp8_transpose_cache_when_using_custom_fsdp . False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   kv_channels ..................................... 128[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   kv_lora_rank .................................... 512[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   langrl_env_config ............................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   langrl_inference_server_conversation_template ... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   langrl_inference_server_type .................... inplace_megatron[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   lazy_mpu_init ................................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   legacy_tokenizer ................................ False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   load ............................................ None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   load_main_params_from_ckpt ...................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   local_rank ...................................... 0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   log_avg_reset_interval .......................... 5[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   log_avg_skip_iterations ......................... 2[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   log_batch_size_to_tensorboard ................... True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   log_interval .................................... 1[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   log_learning_rate_to_tensorboard ................ True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   log_loss_scale_to_tensorboard ................... True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   log_memory_to_tensorboard ....................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   log_num_zeros_in_grad ........................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   log_params_norm ................................. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   log_progress .................................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   log_straggler ................................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   log_throughput .................................. True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   log_timers_to_tensorboard ....................... True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   log_validation_ppl_to_tensorboard ............... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   log_world_size_to_tensorboard ................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   logging_level ................................... 10[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   loss_scale ...................................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   loss_scale_window ............................... 1000[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   lr .............................................. 1e-05[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   lr_decay_iters .................................. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   lr_decay_samples ................................ None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   lr_decay_style .................................. cosine[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   lr_warmup_fraction .............................. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   lr_warmup_init .................................. 0.0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   lr_warmup_iters ................................. 2[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   lr_warmup_samples ............................... 0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   lr_wsd_decay_iters .............................. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   lr_wsd_decay_samples ............................ None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   lr_wsd_decay_style .............................. exponential[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   main_grads_dtype ................................ torch.float32[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   main_params_dtype ............................... torch.float32[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   make_vocab_size_divisible_by .................... 128[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   mamba_head_dim .................................. 64[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   mamba_num_groups ................................ 8[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   mamba_num_heads ................................. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   mamba_state_dim ................................. 128[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   manual_gc ....................................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   manual_gc_eval .................................. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   manual_gc_interval .............................. 1[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   mask_factor ..................................... 1.0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   mask_prob ....................................... 0.15[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   mask_type ....................................... random[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   masked_softmax_fusion ........................... True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   max_position_embeddings ......................... 4096[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   max_tokens_to_oom ............................... 12000[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   memory_snapshot_path ............................ snapshot.pickle[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   merge_file ...................................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   micro_batch_size ................................ 1[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   microbatch_group_size_per_vp_stage .............. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   min_loss_scale .................................. 1.0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   min_lr .......................................... 0.0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   mlflow_experiment_name .......................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   mlflow_run_name ................................. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   mmap_bin_files .................................. True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   mock_data ....................................... True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   moe_aux_loss_coeff .............................. 0.001[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   moe_enable_deepep ............................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   moe_expert_capacity_factor ...................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   moe_extended_tp ................................. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   moe_ffn_hidden_size ............................. 1408[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   moe_grouped_gemm ................................ True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   moe_input_jitter_eps ............................ None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   moe_layer_freq .................................. [0, 1, 1, 1, 1, 1, 1, 1][0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   moe_layer_recompute ............................. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   moe_pad_expert_input_to_capacity ................ False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   moe_per_layer_logging ........................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   moe_permute_fusion .............................. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   moe_router_bias_update_rate ..................... 0.001[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   moe_router_dtype ................................ None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   moe_router_enable_expert_bias ................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   moe_router_force_load_balancing ................. True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   moe_router_group_topk ........................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   moe_router_load_balancing_type .................. seq_aux_loss[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   moe_router_num_groups ........................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   moe_router_pre_softmax .......................... True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   moe_router_score_function ....................... softmax[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   moe_router_topk ................................. 6[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   moe_router_topk_scaling_factor .................. 1.0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   moe_shared_expert_intermediate_size ............. 2816[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   moe_shared_expert_overlap ....................... True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   moe_token_dispatcher_type ....................... alltoall[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   moe_token_drop_policy ........................... probs[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   moe_use_fused_router_with_aux_score ............. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   moe_use_legacy_grouped_gemm ..................... True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   moe_use_upcycling ............................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   moe_z_loss_coeff ................................ None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   mscale .......................................... 0.707[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   mscale_all_dim .................................. 0.707[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   mtp_loss_scaling_factor ......................... 0.1[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   mtp_num_layers .................................. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   multi_latent_attention .......................... True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   multiple_validation_sets ........................ False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   name ............................................ pre_trainer[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   nccl_communicator_config_path ................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   no_fp8_weight_transpose_cache ................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   no_load_optim ................................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   no_load_rng ..................................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   no_persist_layer_norm ........................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   no_save_optim ................................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   no_save_rng ..................................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   non_persistent_ckpt_type ........................ None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   non_persistent_global_ckpt_dir .................. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   non_persistent_local_ckpt_algo .................. fully_parallel[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   non_persistent_local_ckpt_dir ................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   non_persistent_save_interval .................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   norm_epsilon .................................... 1e-06[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   normalization ................................... RMSNorm[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   num_attention_heads ............................. 16[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   num_channels .................................... 3[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   num_classes ..................................... 1000[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   num_dataset_builder_threads ..................... 1[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   num_distributed_optimizer_instances ............. 1[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   num_experts ..................................... 64[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   num_layers ...................................... 8[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   num_layers_at_end_in_bf16 ....................... 1[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   num_layers_at_start_in_bf16 ..................... 1[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   num_layers_per_virtual_pipeline_stage ........... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   num_query_groups ................................ None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   num_seq_splits .................................. 1[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   num_virtual_stages_per_pipeline_rank ............ 2[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   num_workers ..................................... 1[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   offload_chunk_num ............................... 0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   offload_overlap_sr .............................. True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   offload_time .................................... 1.0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   one_logger_async ................................ False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   one_logger_project .............................. megatron-lm[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   one_logger_run_name ............................. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   onnx_safe ....................................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   openai_gelu ..................................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   optimizer ....................................... adam[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   optimizer_cpu_offload ........................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   optimizer_offload_fraction ...................... 1.0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   output_bert_embeddings .......................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   overlap_cpu_optimizer_d2h_h2d ................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   overlap_grad_reduce ............................. True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   overlap_moe_expert_parallel_comm ................ False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   overlap_p2p_comm ................................ True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   overlap_param_gather ............................ True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   overlap_param_gather_with_optimizer_step ........ False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   override_opt_param_scheduler .................... True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   parallel_output ................................. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   params_dtype .................................... torch.bfloat16[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   patch_dim ....................................... 16[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   patch_zero_bubble ............................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   per_split_data_args_path ........................ None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   perform_initialization .......................... True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   perform_rl_step ................................. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   pin_cpu_grads ................................... True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   pin_cpu_params .................................. True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   pipeline_model_parallel_comm_backend ............ None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   pipeline_model_parallel_layout .................. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   pipeline_model_parallel_size .................... 4[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   pipeline_model_parallel_split_rank .............. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   position_embedding_type ......................... rope[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   pp_warmup ....................................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   pre_communication_optimization .................. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   pretrained_checkpoint ........................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   profile ......................................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   profile_memory_iter ............................. -1[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   profile_ranks ................................... [0][0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   profile_step_end ................................ 12[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   profile_step_start .............................. 10[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   q_lora_rank ..................................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   qk_head_dim ..................................... 128[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   qk_l2_norm ...................................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   qk_layernorm .................................... True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   qk_pos_emb_head_dim ............................. 64[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   query_in_block_prob ............................. 0.1[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   quick_geglu ..................................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   rampup_batch_size ............................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   rank ............................................ 0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   recompute_granularity ........................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   recompute_method ................................ None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   recompute_num_layers ............................ None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   record_memory_history ........................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   replication ..................................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   replication_factor .............................. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   replication_jump ................................ None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   rerun_mode ...................................... disabled[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   reset_attention_mask ............................ False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   reset_position_ids .............................. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   result_rejected_tracker_filename ................ None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   retriever_report_topk_accuracies ................ [][0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   retriever_score_scaling ......................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   retriever_seq_length ............................ 256[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   retro_add_retriever ............................. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   retro_attention_gate ............................ 1[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   retro_cyclic_train_iters ........................ None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   retro_encoder_attention_dropout ................. 0.1[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   retro_encoder_hidden_dropout .................... 0.1[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   retro_encoder_layers ............................ 2[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   retro_num_neighbors ............................. 2[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   retro_num_retrieved_chunks ...................... 2[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   retro_project_dir ............................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   retro_verify_neighbor_count ..................... True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   rl_calculate_intra_group_similarity ............. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   rl_importance_sampling_truncation_coef .......... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   rl_inference_logprobs_is_correction ............. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   rl_offload_kv_cache_during_training ............. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   rl_offload_optimizer_during_inference ........... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   rl_partial_rollouts ............................. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   rl_prompts_per_eval ............................. 32[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   rl_remove_kv_cache_during_training .............. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   rl_reset_cuda_graphs ............................ False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   rope_scaling_factor ............................. 8.0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   rope_type ....................................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   rotary_base ..................................... 10000[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   rotary_interleaved .............................. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   rotary_percent .................................. 1.0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   rotary_scaling_factor ........................... 40.0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   rotary_seq_len_interpolation_factor ............. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   router_logit_softcapping ........................ None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   run_workload_inspector_server ................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   s3_cache_path ................................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   sample_rate ..................................... 1.0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   save ............................................ /shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/output/amd/root/tests/trainer/test_megatron_trainer.yaml/checkpoints[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   save_interval ................................... 20000[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   save_retain_interval ............................ None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   scatter_gather_tensors_in_pipeline .............. True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   seed ............................................ 1234[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   seq_length ...................................... 4096[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   sequence_parallel ............................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   sgd_momentum .................................... 0.9[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   sharp_enabled_group ............................. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   short_seq_prob .................................. 0.1[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   sink_level ...................................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   skip_train ...................................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   skipped_train_samples ........................... 0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   spec ............................................ None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   split ........................................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   squared_relu .................................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   standalone_embedding_stage ...................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   start_weight_decay .............................. 0.1[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   stderr_sink_level ............................... DEBUG[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   straggler_ctrlr_port ............................ 65535[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   straggler_minmax_count .......................... 1[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   suggested_communication_unit_size ............... 400000000[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   swiglu .......................................... True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   swin_backbone_type .............................. tiny[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   te_rng_tracker .................................. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   tensor_model_parallel_size ...................... 1[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   tensorboard_dir ................................. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   tensorboard_log_interval ........................ 1[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   tensorboard_queue_size .......................... 1000[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   test_data_path .................................. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   test_mode ....................................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   tiktoken_num_special_tokens ..................... 1000[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   tiktoken_pattern ................................ None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   tiktoken_special_tokens ......................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   timing_log_level ................................ 0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   timing_log_option ............................... minmax[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   titles_data_path ................................ None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   tokenizer_model ................................. deepseek-ai/DeepSeek-V2-Lite[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   tokenizer_type .................................. DeepSeekV2Tokenizer[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   torch_profiler_record_shapes .................... True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   torch_profiler_use_gzip ......................... True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   torch_profiler_with_stack ....................... True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   tp_comm_bootstrap_backend ....................... nccl[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   tp_comm_bulk_dgrad .............................. True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   tp_comm_bulk_wgrad .............................. True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   tp_comm_overlap ................................. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   tp_comm_overlap_ag .............................. True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   tp_comm_overlap_cfg ............................. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   tp_comm_overlap_rs .............................. True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   tp_comm_overlap_rs_dgrad ........................ False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   tp_comm_split_ag ................................ True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   tp_comm_split_rs ................................ True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   train_data_path ................................. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   train_iters ..................................... 3[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   train_samples ................................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   train_sync_interval ............................. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   trainable ....................................... True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   transformer_impl ................................ transformer_engine[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   transformer_pipeline_model_parallel_size ........ 4[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   trust_remote_code ............................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   turbo_deepep_num_cu ............................. 32[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   turbo_deepep_use_comm_stream .................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   turbo_sync_free_moe_stage ....................... 0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   untie_embeddings_and_output_weights ............. True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   use_checkpoint_args ............................. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   use_checkpoint_opt_param_scheduler .............. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   use_cpu_initialization .......................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   use_custom_fsdp ................................. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   use_deprecated_20241209_moe_layer ............... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   use_dist_ckpt ................................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   use_dist_ckpt_deprecated ........................ False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   use_distributed_optimizer ....................... True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   use_flash_attn .................................. True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   use_legacy_models ............................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   use_megatron_fsdp ............................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   use_mp_args_from_checkpoint_args ................ False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   use_one_sent_docs ............................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   use_persistent_ckpt_worker ...................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   use_precision_aware_optimizer ................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   use_pytorch_profiler ............................ False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   use_ring_exchange_p2p ........................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   use_rocm_mem_info ............................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   use_rocm_mem_info_iters ......................... [1, 2][0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   use_rope_scaling ................................ False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   use_rotary_position_embeddings .................. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   use_sharp ....................................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   use_te_activation_func .......................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   use_tokenizer_model_from_checkpoint_args ........ True[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   use_torch_fsdp2 ................................. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   use_torch_optimizer_for_cpu_offload ............. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   use_tp_pp_dp_mapping ............................ False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   use_turbo_attention ............................. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   use_turbo_deepep ................................ False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   use_turbo_fused_act_with_probs .................. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   use_turbo_grouped_mlp ........................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   use_turbo_parallel_linear ....................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   v_head_dim ...................................... 128[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   valid_data_path ................................. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   variable_seq_lengths ............................ False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   virtual_pipeline_model_parallel_size ............ 2[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   vision_backbone_type ............................ vit[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   vision_pretraining .............................. False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   vision_pretraining_type ......................... classify[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   vocab_extra_ids ................................. 0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   vocab_file ...................................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   vocab_size ...................................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   wandb_entity .................................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   wandb_exp_name .................................. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   wandb_project ................................... None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   wandb_save_dir .................................. None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   weight_decay .................................... 0.1[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   weight_decay_incr_style ......................... constant[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   wgrad_deferral_limit ............................ 0[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   world_size ...................................... 8[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   yaml_cfg ........................................ None[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   zero_bubble_adaptive_memory_limit_percentile .... 85[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   zero_bubble_max_pending_backward ................ auto[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   zero_bubble_pipeline_timers_end_iter ............ 110[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   zero_bubble_pipeline_timers_start_iter .......... 100[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   zero_bubble_v_schedule .......................... False[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1198] :   zero_bubble_v_schedule_mem_setup ................ half[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1199] : -------------------- end of arguments ---------------------[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[--------trainer.py:1116] : -monkey patch megatron.training.global_vars._set_wandb_writer...[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[--------trainer.py:1121] : -set_global_variables...[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[--------trainer.py:1123] : -set_primus_global_variables...[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[--------trainer.py:1128] : -build_tokenizer...[0m
[[32m20251030 07:30:51[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[--------tokenizer.py:40] : -building DeepSeekV2Tokenizer tokenizer...[0m
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1[Gloo] Rank  is connected to 10 peer ranks.  is connected to Expected number of connected peer ranks is : 11 peer ranks. Expected number of connected peer ranks is :
1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to [Gloo] Rank 1 peer ranks. Expected number of connected peer ranks is : 10
 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0[Gloo] Rank  is connected to 1 peer ranks. Expected number of connected peer ranks is : 11 is connected to 1
 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[[32m20251030 07:30:52[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[--------tokenizer.py:63] :  > padded vocab (size: 100002) with 94 dummy tokens (new size: 100096)[0m
RerunStateMachine initialized in mode disabled
[[32m20251030 07:30:52[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[--------trainer.py:1181] : -lazy_mpu_init:     None[0m
[[32m20251030 07:30:52[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[--------trainer.py:1158] : -initialize_distributed...[0m
[[32m20251030 07:30:52[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------initialize.py:329] : > initializing torch distributed ...[0m
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to [Gloo] Rank 1 peer ranks. 0Expected number of connected peer ranks is :  is connected to 11
 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[[32m20251030 07:30:52[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------initialize.py:380] : > initialized tensor model parallel with size 1[0m
[[32m20251030 07:30:52[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------initialize.py:384] : > initialized pipeline model parallel with size 4[0m
[[32m20251030 07:30:52[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[--------trainer.py:1162] : -seeds:             1234[0m
[[32m20251030 07:30:56[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:706] : time to initialize megatron (seconds): 5.737[0m
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
[[32m20251030 07:30:56[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:385] : [after megatron is initialized] datetime: 2025-10-30 07:30:56 [0m
[[32m20251030 07:30:56[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:939] : -setup_model_and_optimizer...[0m
[[32m20251030 07:30:56[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[--------trainer.py:1232] : use te backend...[0m
[[32m20251030 07:30:56[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[--------trainer.py:1238] : -run get_model[0m
/shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM/megatron/core/transformer/transformer_config.py:1458: UserWarning: Using a large number of experts (e.g. >=32) without fp32 routing. Consider enabling moe_router_dtype for better numerical stability.
  warnings.warn(
/shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM/megatron/core/transformer/transformer_config.py:1458: UserWarning: Using a large number of experts (e.g. >=32) without fp32 routing. Consider enabling moe_router_dtype for better numerical stability.
  warnings.warn(
/shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM/megatron/core/transformer/transformer_config.py:1458: UserWarning: Using a large number of experts (e.g. >=32) without fp32 routing. Consider enabling moe_router_dtype for better numerical stability.
  warnings.warn(
/shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM/megatron/core/transformer/transformer_config.py:1458: UserWarning: Using a large number of experts (e.g. >=32) without fp32 routing. Consider enabling moe_router_dtype for better numerical stability.
  warnings.warn(
/shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM/megatron/core/extensions/transformer_engine_spec_provider.py:74: UserWarning: The legacy GroupedMLP will be deprecated in Megatron-Core v0.12.0. Please update the TransformerEngine to version>=1.7.0 and use TEGroupedMLP.
  warnings.warn(
/shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM/megatron/core/extensions/transformer_engine_spec_provider.py:74: UserWarning: The legacy GroupedMLP will be deprecated in Megatron-Core v0.12.0. Please update the TransformerEngine to version>=1.7.0 and use TEGroupedMLP.
  warnings.warn(
/shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM/megatron/core/extensions/transformer_engine_spec_provider.py:74: UserWarning: The legacy GroupedMLP will be deprecated in Megatron-Core v0.12.0. Please update the TransformerEngine to version>=1.7.0 and use TEGroupedMLP.
  warnings.warn(
/shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM/megatron/core/extensions/transformer_engine_spec_provider.py:74: UserWarning: The legacy GroupedMLP will be deprecated in Megatron-Core v0.12.0. Please update the TransformerEngine to version>=1.7.0 and use TEGroupedMLP.
  warnings.warn(
/shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM/megatron/core/transformer/transformer_config.py:1458: UserWarning: Using a large number of experts (e.g. >=32) without fp32 routing. Consider enabling moe_router_dtype for better numerical stability.
  warnings.warn(
/shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM/megatron/core/transformer/transformer_config.py:1458: UserWarning: Using a large number of experts (e.g. >=32) without fp32 routing. Consider enabling moe_router_dtype for better numerical stability.
  warnings.warn(
/shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM/megatron/core/transformer/transformer_config.py:1458: UserWarning: Using a large number of experts (e.g. >=32) without fp32 routing. Consider enabling moe_router_dtype for better numerical stability.
  warnings.warn(
/shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM/megatron/core/extensions/transformer_engine_spec_provider.py:74: UserWarning: The legacy GroupedMLP will be deprecated in Megatron-Core v0.12.0. Please update the TransformerEngine to version>=1.7.0 and use TEGroupedMLP.
  warnings.warn(
/shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM/megatron/core/extensions/transformer_engine_spec_provider.py:74: UserWarning: The legacy GroupedMLP will be deprecated in Megatron-Core v0.12.0. Please update the TransformerEngine to version>=1.7.0 and use TEGroupedMLP.
  warnings.warn(
/shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM/megatron/core/extensions/transformer_engine_spec_provider.py:74: UserWarning: The legacy GroupedMLP will be deprecated in Megatron-Core v0.12.0. Please update the TransformerEngine to version>=1.7.0 and use TEGroupedMLP.
  warnings.warn(
[[32m20251030 07:30:56[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:385] : building GPT model ...[0m
/shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM/megatron/core/transformer/transformer_config.py:1458: UserWarning: Using a large number of experts (e.g. >=32) without fp32 routing. Consider enabling moe_router_dtype for better numerical stability.
  warnings.warn(
/shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM/megatron/core/extensions/transformer_engine_spec_provider.py:74: UserWarning: The legacy GroupedMLP will be deprecated in Megatron-Core v0.12.0. Please update the TransformerEngine to version>=1.7.0 and use TEGroupedMLP.
  warnings.warn(
[[32m20251030 07:30:56[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:385] : building GPT model ...[0m
[[32m20251030 07:30:56[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[--------training.py:903] :  > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 870851584[0m
[[32m20251030 07:30:56[0m][[36mrank-4/8[0m][[34m[1mDEBUG[0m] [34m[1m[--------training.py:903] :  > number of parameters on (tensor, pipeline) model parallel rank (0, 2): 1169695744[0m
[[32m20251030 07:30:56[0m][[36mrank-2/8[0m][[34m[1mDEBUG[0m] [34m[1m[--------training.py:903] :  > number of parameters on (tensor, pipeline) model parallel rank (0, 1): 1169695744[0m
[[32m20251030 07:30:56[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[--------trainer.py:1240] : [DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0): TransformerLayer(
            (input_layernorm): RMSNorm()
            (self_attention): MLASelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear(in_features=2048, out_features=2048, bias=False, TP=1)
              (rotary_pos_emb): YarnRotaryEmbedding()
              (linear_q_proj): TEColumnParallelLinear(in_features=2048, out_features=3072, bias=False, TP=1)
              (linear_kv_down_proj): TELinear()
              (linear_kv_up_proj): TELayerNormColumnParallelLinear(in_features=512, out_features=4096, bias=False, TP=1)
              (kv_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): IdentityOp()
            (mlp): MLP(
              (linear_fc1): TELayerNormColumnParallelLinear(in_features=2048, out_features=21888, bias=False, TP=1)
              (linear_fc2): TERowParallelLinear(in_features=10944, out_features=2048, bias=False, TP=1)
            )
          )
        )
      )
    )
  )
), DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0): TransformerLayer(
            (input_layernorm): RMSNorm()
            (self_attention): MLASelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear(in_features=2048, out_features=2048, bias=False, TP=1)
              (rotary_pos_emb): YarnRotaryEmbedding()
              (linear_q_proj): TEColumnParallelLinear(in_features=2048, out_features=3072, bias=False, TP=1)
              (linear_kv_down_proj): TELinear()
              (linear_kv_up_proj): TELayerNormColumnParallelLinear(in_features=512, out_features=4096, bias=False, TP=1)
              (kv_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): PrimusTopKRouter()
              (experts): GroupedMLP()
              (shared_experts): SharedExpertMLP(
                (linear_fc1): TEColumnParallelLinear(in_features=2048, out_features=5632, bias=False, TP=1)
                (linear_fc2): TERowParallelLinear(in_features=2816, out_features=2048, bias=False, TP=1)
              )
            )
          )
        )
      )
    )
  )
)][0m
[[32m20251030 07:30:57[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[--------trainer.py:1254] : -run get_megatron_optimizer[0m
[[32m20251030 07:30:57[0m][[36mrank-6/8[0m][[34m[1mDEBUG[0m] [34m[1m[--------training.py:903] :  > number of parameters on (tensor, pipeline) model parallel rank (0, 3): 1374694400[0m
[[32m20251030 07:30:57[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:385] : [after model, optimizer, and learning rate scheduler are built] datetime: 2025-10-30 07:30:57 [0m
[[32m20251030 07:30:57[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:385] : > building train, validation, and test datasets ...[0m
[[32m20251030 07:30:57[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:385] :  > datasets target sizes (minimum size):[0m
[[32m20251030 07:30:57[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:385] :     train:      48[0m
[[32m20251030 07:30:57[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:385] :     validation: 0[0m
[[32m20251030 07:30:57[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:385] :     test:       0[0m
[[32m20251030 07:30:57[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[--------trainer.py:1045] : > building train, validation, and test datasets for GPT ...[0m
Unable to save MockGPTDataset indexes because path_to_cache is None
Unable to save MockGPTDataset indexes because path_to_cache is None
Unable to save MockGPTDataset indexes because path_to_cache is None
[[32m20251030 07:30:57[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[--------trainer.py:1050] : > finished creating GPT datasets ...[0m
[[32m20251030 07:30:57[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:385] : > building train, validation, and test datasets ...[0m
[[32m20251030 07:30:57[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:385] :  > datasets target sizes (minimum size):[0m
[[32m20251030 07:30:57[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:385] :     train:      48[0m
[[32m20251030 07:30:57[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:385] :     validation: 0[0m
[[32m20251030 07:30:57[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:385] :     test:       0[0m
[[32m20251030 07:30:57[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[--------trainer.py:1045] : > building train, validation, and test datasets for GPT ...[0m
Unable to save MockGPTDataset indexes because path_to_cache is None
Unable to save MockGPTDataset indexes because path_to_cache is None
Unable to save MockGPTDataset indexes because path_to_cache is None
[[32m20251030 07:30:57[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[--------trainer.py:1050] : > finished creating GPT datasets ...[0m
[[32m20251030 07:30:57[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:385] : [after dataloaders are built] datetime: 2025-10-30 07:30:57 [0m
[[32m20251030 07:30:57[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:992] : done with setup ...[0m
[[32m20251030 07:30:57[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[--------trainer.py:1384] : training ...[0m
[[32m20251030 07:30:57[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[--------trainer.py:1528] : Setting rerun_state_machine.current_iteration to 0...[0m
[[32m20251030 07:30:57[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[-----import_utils.py:30] : [Primus][MegatronCompat] Loaded FullyShardedDataParallel from megatron.core.distributed.fsdp.mcore_fsdp_adapter[0m
[[32m20251030 07:30:57[0m][[36mrank-7/8[0m][[34m[1mDEBUG[0m] [34m[1m[----------timers.py:430] : (min, max) time across ranks (ms):
    model-and-optimizer-setup ......................: (390.95, 391.09)
    train/valid/test-data-iterators-setup ..........: (22.87, 24.20)[0m
[[32m20251030 07:30:57[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:385] : [before the start of training step] datetime: 2025-10-30 07:30:57 [0m
[rank5]:[W1030 07:30:57.004124789 ProcessGroupNCCL.cpp:3996] Warning: An unbatched P2P op (send/recv) was called on this ProcessGroup with size 4.  In lazy initialization mode, this will result in a new 2-rank NCCL communicator to be created. (function operator())
[rank2]:[W1030 07:30:57.004143827 ProcessGroupNCCL.cpp:3996] Warning: An unbatched P2P op (send/recv) was called on this ProcessGroup with size 4.  In lazy initialization mode, this will result in a new 2-rank NCCL communicator to be created. (function operator())
[rank7]:[W1030 07:30:57.004234723 ProcessGroupNCCL.cpp:3996] Warning: An unbatched P2P op (send/recv) was called on this ProcessGroup with size 4.  In lazy initialization mode, this will result in a new 2-rank NCCL communicator to be created. (function operator())
[rank6]:[W1030 07:30:57.004266060 ProcessGroupNCCL.cpp:3996] Warning: An unbatched P2P op (send/recv) was called on this ProcessGroup with size 4.  In lazy initialization mode, this will result in a new 2-rank NCCL communicator to be created. (function operator())
[rank3]:[W1030 07:30:57.004301242 ProcessGroupNCCL.cpp:3996] Warning: An unbatched P2P op (send/recv) was called on this ProcessGroup with size 4.  In lazy initialization mode, this will result in a new 2-rank NCCL communicator to be created. (function operator())
[rank4]:[W1030 07:30:57.004342224 ProcessGroupNCCL.cpp:3996] Warning: An unbatched P2P op (send/recv) was called on this ProcessGroup with size 4.  In lazy initialization mode, this will result in a new 2-rank NCCL communicator to be created. (function operator())
[rank1]:[W1030 07:31:01.632337055 ProcessGroupNCCL.cpp:3996] Warning: An unbatched P2P op (send/recv) was called on this ProcessGroup with size 4.  In lazy initialization mode, this will result in a new 2-rank NCCL communicator to be created. (function operator())
[rank1]:[W1030 07:31:02.983361867 ProcessGroupNCCL.cpp:3996] Warning: An unbatched P2P op (send/recv) was called on this ProcessGroup with size 4.  In lazy initialization mode, this will result in a new 2-rank NCCL communicator to be created. (function operator())
[rank0]:[W1030 07:31:03.955132420 ProcessGroupNCCL.cpp:3996] Warning: An unbatched P2P op (send/recv) was called on this ProcessGroup with size 4.  In lazy initialization mode, this will result in a new 2-rank NCCL communicator to be created. (function operator())
[rank0]:[W1030 07:31:03.294361080 ProcessGroupNCCL.cpp:3996] Warning: An unbatched P2P op (send/recv) was called on this ProcessGroup with size 4.  In lazy initialization mode, this will result in a new 2-rank NCCL communicator to be created. (function operator())
[rank3]:[W1030 07:31:06.395270475 ProcessGroupNCCL.cpp:3996] Warning: An unbatched P2P op (send/recv) was called on this ProcessGroup with size 4.  In lazy initialization mode, this will result in a new 2-rank NCCL communicator to be created. (function operator())
[rank2]:[W1030 07:31:07.771771281 ProcessGroupNCCL.cpp:3996] Warning: An unbatched P2P op (send/recv) was called on this ProcessGroup with size 4.  In lazy initialization mode, this will result in a new 2-rank NCCL communicator to be created. (function operator())
[rank5]:[W1030 07:31:11.220718648 ProcessGroupNCCL.cpp:3996] Warning: An unbatched P2P op (send/recv) was called on this ProcessGroup with size 4.  In lazy initialization mode, this will result in a new 2-rank NCCL communicator to be created. (function operator())
[rank4]:[W1030 07:31:12.621622738 ProcessGroupNCCL.cpp:3996] Warning: An unbatched P2P op (send/recv) was called on this ProcessGroup with size 4.  In lazy initialization mode, this will result in a new 2-rank NCCL communicator to be created. (function operator())
[rank7]:[W1030 07:31:16.390751984 ProcessGroupNCCL.cpp:3996] Warning: An unbatched P2P op (send/recv) was called on this ProcessGroup with size 4.  In lazy initialization mode, this will result in a new 2-rank NCCL communicator to be created. (function operator())
[rank6]:[W1030 07:31:17.773921819 ProcessGroupNCCL.cpp:3996] Warning: An unbatched P2P op (send/recv) was called on this ProcessGroup with size 4.  In lazy initialization mode, this will result in a new 2-rank NCCL communicator to be created. (function operator())
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
[[32m20251030 07:31:34[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[theoretical_memory_usage.py:137] : Number of parameters in transformer block in billions:  4.17[0m
[[32m20251030 07:31:34[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[theoretical_memory_usage.py:146] : Number of parameters in embedding layers in billions: 0.41[0m
[[32m20251030 07:31:34[0m][[36mrank-7/8[0m][[1mINFO [0m] [1m[--------trainer.py:2509] :  iteration        1/       3 | consumed samples:           16 | elapsed time per iteration (ms): 36958.6/36958.6 | hip mem usage/free/total/usage_ratio: 29.15GB/162.83GB/191.98GB/15.19% | rocm mem usage/free/total/usage_ratio: 30.22GB/161.76GB/191.98GB/15.74% | throughput per GPU (TFLOP/s/GPU): 1.4/1.4 | tokens per GPU (tokens/s/GPU): 221.7/221.7 | learning rate: 5.000000E-06 | global batch size:    16 | lm loss: 1.157208E+01 | loss scale: 1.0 | grad norm: 5.303 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251030 07:31:34[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[theoretical_memory_usage.py:150] : Total number of parameters in billions: 4.58[0m
[[32m20251030 07:31:34[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[theoretical_memory_usage.py:163] : Number of parameters in most loaded shard in billions: 1.2485[0m
[[32m20251030 07:31:34[0m][[36mrank-4/8[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:275] : [Rank 4] (after 1 iterations) memory (MB) | allocated: 13493.916015625 | max allocated: 13803.4970703125 | reserved: 17392.0 | max reserved: 17392.0[0m
[[32m20251030 07:31:34[0m][[36mrank-2/8[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:275] : [Rank 2] (after 1 iterations) memory (MB) | allocated: 13493.4248046875 | max allocated: 14774.2509765625 | reserved: 18800.0 | max reserved: 18800.0[0m
[[32m20251030 07:31:34[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[theoretical_memory_usage.py:174] : Number of parameters in other shards in billions: 1.0435[0m
[[32m20251030 07:31:34[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:385] : compute_activation_memory_without_sp[0m
[[32m20251030 07:31:34[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[theoretical_memory_usage.py:270] : Activation memory footprint per transformer layer (precise, without SP): 272.0 MB[0m
[[32m20251030 07:31:34[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[theoretical_memory_usage.py:302] : Memory penalty from interleaved schedule: 1.38[0m
[[32m20251030 07:31:34[0m][[36mrank-6/8[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:275] : [Rank 6] (after 1 iterations) memory (MB) | allocated: 15990.458984375 | max allocated: 15990.46337890625 | reserved: 19116.0 | max reserved: 19116.0[0m
[[32m20251030 07:31:34[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[theoretical_memory_usage.py:305] : Number of in-flight microbatches: 6[0m
[[32m20251030 07:31:34[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[theoretical_memory_usage.py:362] : Theoretical memory footprints: weight and optimizer=14288.09 MB, activation=3187.98 MB, total=17476.07 MB
[0m
[[32m20251030 07:31:34[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:275] : [Rank 0] (after 1 iterations) memory (MB) | allocated: 10041.49609375 | max allocated: 12758.4599609375 | reserved: 17182.0 | max reserved: 17182.0[0m
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
[[32m20251030 07:31:35[0m][[36mrank-7/8[0m][[1mINFO [0m] [1m[--------trainer.py:2509] :  iteration        2/       3 | consumed samples:           32 | elapsed time per iteration (ms): 1178.4/19068.5 | hip mem usage/free/total/usage_ratio: 31.71GB/160.27GB/191.98GB/16.52% | rocm mem usage/free/total/usage_ratio: 32.78GB/159.20GB/191.98GB/17.08% | throughput per GPU (TFLOP/s/GPU): 43.2/22.3 | tokens per GPU (tokens/s/GPU): 6951.7/3586.7 | learning rate: 1.000000E-05 | global batch size:    16 | lm loss: 1.157245E+01 | loss scale: 1.0 | grad norm: 5.312 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251030 07:31:36[0m][[36mrank-7/8[0m][[1mINFO [0m] [1m[--------trainer.py:2509] :  iteration        3/       3 | consumed samples:           48 | elapsed time per iteration (ms): 846.5/846.5 | hip mem usage/free/total/usage_ratio: 31.71GB/160.27GB/191.98GB/16.52% | throughput per GPU (TFLOP/s/GPU): 60.2/60.2 | tokens per GPU (tokens/s/GPU): 9677.4/9677.4 | learning rate: 0.000000E+00 | global batch size:    16 | lm loss: 1.143753E+01 | loss scale: 1.0 | grad norm: 5.259 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251030 07:31:36[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:385] : [after training is done] datetime: 2025-10-30 07:31:36 [0m
