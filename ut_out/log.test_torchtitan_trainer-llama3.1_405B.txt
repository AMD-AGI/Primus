W1031 08:23:57.850000 136137 torch/distributed/run.py:803]
W1031 08:23:57.850000 136137 torch/distributed/run.py:803] *****************************************
W1031 08:23:57.850000 136137 torch/distributed/run.py:803] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
W1031 08:23:57.850000 136137 torch/distributed/run.py:803] *****************************************
[Primus CLI] HF_HOME already set: /shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/data/huggingface
[PrimusConfig] Detected unknown override keys: ['model']
[Primus] sys.path.insert: /shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/torchtitan
[[32m20251031 08:23:59[0m][[36mrank-1/8[0m][[33m[1mWARNING[0m] [33m[1m[PrimusPatch][AMP] nn.Embedding.__init__ patched for AMP/mixed precision alignment.[0m
[[32m20251031 08:23:59[0m][[36mrank-1/8[0m][[33m[1mWARNING[0m] [33m[1m[PrimusPatch][Dataset] Patched datasets.load_dataset successfully.[0m
[[32m20251031 08:24:00[0m][[36mrank-1/8[0m][[33m[1mWARNING[0m] [33m[1m[PrimusPatch][DCP] Installed fallback for missing torch.distributed.checkpoint._consolidate_hf_safetensors.consolidate_safetensors_files_on_every_rank, HuggingFace safetensors export will be disabled.[0m
[[32m20251031 08:24:00[0m][[36mrank-1/8[0m][[33m[1mWARNING[0m] [33m[1m[PrimusPatch][Pipe] Installed fallback: ScheduleDualPipeV -> Schedule1F1B[0m
[[32m20251031 08:24:00[0m][[36mrank-1/8[0m][[33m[1mWARNING[0m] [33m[1m[PrimusPatch][FlexAttn] AuxOutput not found. This torch build predates the new debug/profiling return type. Injecting a lightweight stub so Titan model imports can succeed.[0m
[[32m20251031 08:24:00[0m][[36mrank-1/8[0m][[33m[1mWARNING[0m] [33m[1m[PrimusPatch][FlexAttn] Injected fallback AuxOutput stub (Titan does not rely on this).[0m
[[32m20251031 08:24:00[0m][[36mrank-1/8[0m][[33m[1mWARNING[0m] [33m[1m[PrimusPatch][Checkpoint] checkpoint_wrapper patched successfully[0m
[[32m20251031 08:24:00[0m][[36mrank-1/8[0m][[33m[1mWARNING[0m] [33m[1m[PrimusPatch][ModelOverride] Applying model_overrides: {'model': {'n_layers': 4}}[0m
[[32m20251031 08:24:00[0m][[36mrank-1/8[0m][[33m[1mWARNING[0m] [33m[1m[PrimusPatch][ModelOverride] Applying overrides: {'model.n_layers': 4}[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[33m[1mWARNING[0m] [33m[1m[PrimusPatch][ModelOverride] get_train_spec for 'llama3' successfully monkey patched (flavor=405B).[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mMokey patch torchtitan logger...[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mLoaded and merged custom JobConfig from primus.backends.torchtitan.primus_turbo_extensions.config_extension[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1m========== TorchTitan Config ==========[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments activation_checkpoint.early_stop.................................. False[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments activation_checkpoint.mode........................................ full[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments activation_checkpoint.per_op_sac_force_recompute_mm_shapes_by_fqns ['moe.router.gate'][0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments activation_checkpoint.selective_ac_option......................... 2[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments checkpoint.async_mode............................................. disabled[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments checkpoint.create_seed_checkpoint................................. False[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments checkpoint.enable................................................. False[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments checkpoint.enable_first_step_checkpoint........................... False[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments checkpoint.exclude_from_loading................................... [][0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments checkpoint.export_dtype........................................... float32[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments checkpoint.folder................................................. checkpoint[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments checkpoint.initial_load_in_hf..................................... False[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments checkpoint.initial_load_model_only................................ True[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments checkpoint.initial_load_path...................................... None[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments checkpoint.interval............................................... 500[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments checkpoint.keep_latest_k.......................................... 10[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments checkpoint.last_save_in_hf........................................ False[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments checkpoint.last_save_model_only................................... True[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments checkpoint.load_step.............................................. -1[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments comm.init_timeout_seconds......................................... 300[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments comm.save_traces_folder........................................... comm_traces[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments comm.trace_buf_size............................................... 20000[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments comm.train_timeout_seconds........................................ 100[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments compile.components................................................ ['model', 'loss'][0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments compile.enable.................................................... True[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments experimental.custom_args_module................................... primus.backends.torchtitan.primus_turbo_extensions.config_extension[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments experimental.custom_import........................................ [0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments fault_tolerance.enable............................................ False[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments fault_tolerance.group_size........................................ 0[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments fault_tolerance.min_replica_size.................................. 1[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments fault_tolerance.process_group..................................... gloo[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments fault_tolerance.process_group_timeout_ms.......................... 10000[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments fault_tolerance.replica_id........................................ 0[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments fault_tolerance.semi_sync_method.................................. None[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments float8.emulate.................................................... False[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments float8.enable_fsdp_float8_all_gather.............................. False[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments float8.filter_fqns................................................ [][0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments float8.moe_fqns_prototype......................................... [][0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments float8.precompute_float8_dynamic_scale_for_fsdp................... False[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments float8.recipe_name................................................ None[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments job.config_file................................................... None[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments job.description................................................... Llama 3 405B training[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments job.dump_folder................................................... ./outputs[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments job.print_args.................................................... False[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments lr_scheduler.decay_ratio.......................................... None[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments lr_scheduler.decay_type........................................... linear[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments lr_scheduler.min_lr_factor........................................ 0.0[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments lr_scheduler.warmup_steps......................................... 200[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments memory_estimation.disable_fake_mode............................... False[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments memory_estimation.enable.......................................... False[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments metrics.disable_color_printing.................................... False[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments metrics.enable_tensorboard........................................ False[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments metrics.enable_wandb.............................................. False[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments metrics.log_freq.................................................. 1[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments metrics.save_for_all_ranks........................................ False[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments metrics.save_tb_folder............................................ tb[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments model.converters.................................................. [][0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments model.flavor...................................................... 405B[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments model.hf_assets_path.............................................. /shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/data/torchtitan/Llama-3.1-405B[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments model.name........................................................ llama3[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments model.print_after_conversion...................................... False[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments model.tokenizer_path.............................................. None[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments mx.filter_fqns.................................................... ['output'][0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments mx.moe_fqns_prototype............................................. [][0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments mx.mxfp8_dim1_cast_kernel_choice.................................. triton[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments mx.recipe_name.................................................... mxfp8_cublas[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments optimizer.beta1................................................... 0.9[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments optimizer.beta2................................................... 0.95[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments optimizer.early_step_in_backward.................................. False[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments optimizer.eps..................................................... 1e-08[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments optimizer.implementation.......................................... fused[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments optimizer.lr...................................................... 8e-05[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments optimizer.name.................................................... AdamW[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments optimizer.weight_decay............................................ 0.1[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.context_parallel_degree............................... 1[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.context_parallel_rotate_method........................ allgather[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.data_parallel_replicate_degree........................ 1[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.data_parallel_shard_degree............................ -1[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.disable_loss_parallel................................. False[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.enable_async_tensor_parallel.......................... False[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.enable_compiled_autograd.............................. False[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.expert_parallel_degree................................ 1[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.expert_tensor_parallel_degree......................... 1[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.fsdp_reshard_after_forward............................ default[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.module_fqns_per_model_part............................ None[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.pipeline_parallel_degree.............................. 1[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.pipeline_parallel_first_stage_less_layers............. 1[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.pipeline_parallel_last_stage_less_layers.............. 1[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.pipeline_parallel_layers_per_stage.................... None[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.pipeline_parallel_microbatch_size..................... 1[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.pipeline_parallel_schedule............................ 1F1B[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.pipeline_parallel_schedule_csv........................ [0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.pipeline_parallel_split_points........................ [][0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments parallelism.tensor_parallel_degree................................ 8[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments primus_turbo.enable_attention_float8.............................. False[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments primus_turbo.enable_embedding_autocast............................ True[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments primus_turbo.enable_primus_turbo.................................. False[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments primus_turbo.use_turbo_async_tp................................... True[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments primus_turbo.use_turbo_attention.................................. True[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments primus_turbo.use_turbo_mx_linear.................................. True[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments profiling.enable_memory_snapshot.................................. False[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments profiling.enable_profiling........................................ False[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments profiling.profile_freq............................................ 10[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments profiling.save_memory_snapshot_folder............................. memory_snapshot[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments profiling.save_traces_folder...................................... profile_traces[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments training.dataset.................................................. c4[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments training.dataset_path............................................. None[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments training.deterministic............................................ False[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments training.enable_cpu_offload....................................... False[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments training.gc_debug................................................. False[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments training.gc_freq.................................................. 50[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments training.global_batch_size........................................ -1[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments training.local_batch_size......................................... 2[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments training.max_norm................................................. 1.0[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments training.mixed_precision_param.................................... bfloat16[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments training.mixed_precision_reduce................................... float32[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments training.seed..................................................... None[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments training.seq_len.................................................. 2048[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments training.steps.................................................... 3[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments validation.dataset................................................ c4_validation[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments validation.dataset_path........................................... None[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments validation.enable................................................. False[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments validation.freq................................................... 10[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments validation.local_batch_size....................................... 8[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments validation.seq_len................................................ 2048[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1marguments validation.steps.................................................. -1[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mStarting job: Llama 3 405B training[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[33m[1mWARNING[0m] [33m[1mENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config[0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mBuilding 1-D device mesh with ['tp'], [8][0m
[[32m20251031 08:24:02[0m][[36mrank-1/8[0m][[1mINFO [0m] [1m[GC] Initial GC collection 0.00 seconds[0m
[[32m20251031 08:24:05[0m][[36mrank-1/8[0m][[33m[1mWARNING[0m] [33m[1m[PrimusPatch][ModelOverride] Successfully patched model_args['405B'] for 'llama3' with {'model.n_layers': 4}. Diff(beforeâ†’after): {'_enforced': 'This field is used to enforce all fields have defaults.', 'dim': 16384, 'n_layers': 126, 'n_heads': 128, 'n_kv_heads': 8, 'vocab_size': 128256, 'multiple_of': 4096, 'ffn_dim_multiplier': 1.2, 'norm_eps': 1e-05, 'rope_theta': 500000, 'max_seq_len': 131072, 'depth_init': True, 'use_flex_attn': False, 'attn_mask_type': 'causal', 'eos_id': 0} â†’ {'_enforced': 'This field is used to enforce all fields have defaults.', 'dim': 16384, 'n_layers': 4, 'n_heads': 128, 'n_kv_heads': 8, 'vocab_size': 128256, 'multiple_of': 4096, 'ffn_dim_multiplier': 1.2, 'norm_eps': 1e-05, 'rope_theta': 500000, 'max_seq_len': 131072, 'depth_init': True, 'use_flex_attn': False, 'attn_mask_type': 'causal', 'eos_id': 0}[0m
[[32m20251031 08:24:05[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mLoading tokenizer from tokenizer.json[0m
[[32m20251031 08:24:06[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mPreparing c4 dataset from allenai/c4[0m
[[32m20251031 08:24:06[0m][[36mrank-1/8[0m][[33m[1mWARNING[0m] [33m[1m[PrimusPatch][MockDataset] load_dataset('allenai/c4') is mocked.[0m
[[32m20251031 08:24:06[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mBuilding llama3 405B with TransformerModelArgs(_enforced='This field is used to enforce all fields have defaults.', dim=16384, n_layers=4, n_heads=128, n_kv_heads=8, vocab_size=128256, multiple_of=4096, ffn_dim_multiplier=1.2, norm_eps=1e-05, rope_theta=500000, max_seq_len=2048, depth_init=True, use_flex_attn=False, attn_mask_type='causal', eos_id=0)[0m
[[32m20251031 08:24:06[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mCUDA capacity: AMD Instinct MI300X with 191.98GiB memory[0m
[[32m20251031 08:24:06[0m][[36mrank-1/8[0m][[1mINFO [0m] [1m[34mModel llama3 405B [31msize: 16,953,524,224 total parameters[39m[0m
[[32m20251031 08:24:06[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mCompiling the loss function with torch.compile[0m
[[32m20251031 08:24:06[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mApplied Tensor Parallelism to the model[0m
[[32m20251031 08:24:06[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mApplied full activation checkpointing to the model[0m
[[32m20251031 08:24:06[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mCompiling each TransformerBlock with torch.compile[0m
[[32m20251031 08:24:06[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mPeak FLOPS used for computing MFU: 1.300e+15[0m
[[32m20251031 08:24:06[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mCUDA memory usage for model: 7.91GiB(4.12%)[0m
[[32m20251031 08:24:06[0m][[36mrank-1/8[0m][[33m[1mWARNING[0m] [33m[1mWarmup steps (200) exceed total training steps (3). Adjusting warmup steps to 3.[0m
[[32m20251031 08:24:06[0m][[36mrank-1/8[0m][[33m[1mWARNING[0m] [33m[1mmodel.safetensors.index.json not found at hf_assets_path: /shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/data/torchtitan/Llama-3.1-405B/model.safetensors.index.json.                     Defaulting to saving a single safetensors file if checkpoint is saved in HF format[0m
[[32m20251031 08:24:06[0m][[36mrank-1/8[0m][[33m[1mWARNING[0m] [33m[1mMixed precision training with TP or PP is only supported when FSDP/HSDP/CP is enabled.[0m
[[32m20251031 08:24:06[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mMixed precision training is disabled[0m
[[32m20251031 08:24:06[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mTrainer is initialized with local batch size 2, global batch size 2, gradient accumulation steps 1, sequence length 2048, total steps 3 (warmup 200)[0m
[[32m20251031 08:24:06[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mTraining starts at step 1[0m
/opt/venv/lib/python3.10/site-packages/torch/_inductor/lowering.py:1937: UserWarning: Torchinductor does not support code generation for complex operators. Performance may be worse than eager.
  warnings.warn(
/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:305: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
[[32m20251031 08:24:18[0m][[36mrank-1/8[0m][[1mINFO [0m] [1m[31mstep:  1  [32mloss: 12.2471  [38;2;180;60;0mgrad_norm: 11.0243  [38;2;54;234;195mmemory: 40.38GiB(21.03%)  [34mtps: 43  [36mtflops: 3.91  [35mmfu: 0.30%[39m[0m
[[32m20251031 08:24:18[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mSynchronizing and adjusting timeout for all ProcessGroups to 0:01:40[0m
[[32m20251031 08:24:19[0m][[36mrank-1/8[0m][[1mINFO [0m] [1m[31mstep:  2  [32mloss:  8.5890  [38;2;180;60;0mgrad_norm: 13.8637  [38;2;54;234;195mmemory: 48.21GiB(25.11%)  [34mtps: 770  [36mtflops: 69.81  [35mmfu: 5.37%[39m[0m
[[32m20251031 08:24:19[0m][[36mrank-1/8[0m][[1mINFO [0m] [1m[31mstep:  3  [32mloss: 29.5789  [38;2;180;60;0mgrad_norm: 116.7791  [38;2;54;234;195mmemory: 48.21GiB(25.11%)  [34mtps: 770  [36mtflops: 69.89  [35mmfu: 5.38%[39m[0m
[[32m20251031 08:24:19[0m][[36mrank-1/8[0m][[1mINFO [0m] [1mTraining completed[0m
