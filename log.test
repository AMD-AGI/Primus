W0911 02:07:29.703000 13895 torch/distributed/run.py:766]
W0911 02:07:29.703000 13895 torch/distributed/run.py:766] *****************************************
W0911 02:07:29.703000 13895 torch/distributed/run.py:766] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
W0911 02:07:29.703000 13895 torch/distributed/run.py:766] *****************************************
[Primus] sys.path.insert: /shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM
[Primus] sys.path.insert: /shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM
[WARNING  | root               ]: Supported flash-attn versions are >= 2.1.1, <= 2.7.3. Found flash-attn 3.0.0.post1.
[WARNING  | root               ]: Supported flash-attn versions are >= 2.1.1, <= 2.7.3. Found flash-attn 3.0.0.post1.
[[32m20250911 02:07:41[0m][[36mrank-7/8[0m][[34m[1mDEBUG[0m] [34m[1m[-----global_vars.py:215] : WARNING: one_logger package is required to enable e2e metrics tracking. please go to https://confluence.nvidia.com/display/MLWFO/Package+Repositories for details to install it[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[33m[1mWARNING[0m] [33m[1m[trainer.py:406]: MegatronTrainer: monkey patch TopKRouter...[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[33m[1mWARNING[0m] [33m[1m[trainer.py:276]: MegatronTrainer: monkey patch get_extra_te_kwargs...[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[33m[1mWARNING[0m] [33m[1m[trainer.py:509]: MegatronTrainer: Patching FileSystemWriterAsync...[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[33m[1mWARNING[0m] [33m[1m[trainer.py:521]: MegatronTrainer: Patch FileSystemWriterAsync successfully.[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:536] : -run update_primus_config...[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:645] : -rank:              0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:646] : -local_rank:        0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:647] : -world_size:        8[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:664] : -save:              /shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/output/amd/root/llama3.1_8B-pretrain/checkpoints[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:671] : -auto_continue_train:False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:707] : -disable_tensorboard:True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:708] :   -tensorboard_dir: None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[---------trainer.py:724] : args.wandb_project is disabled, as args.disable_wandb=True.[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:725] : -disable_wandb:     True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:731] :   -wandb_project:   None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:732] :   -wandb_exp_name:  None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:733] :   -wandb_save_dir:  None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:734] :   -wandb_entity:    None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:544] : -run initialize_megatron...[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:948] : -load:              None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:949] : -use_checkpoint_args:False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-------arguments.py:364] : using world size: 8, data-parallel size: 8, context-parallel size: 1, hierarchical context-parallel sizes: Nonetensor-model-parallel size: 1, encoder-tensor-model-parallel size: 0, pipeline-model-parallel size: 1, encoder-pipeline-model-parallel size: 0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-------arguments.py:529] : Number of virtual stages per pipeline stage: None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-------arguments.py:632] : accumulate and all-reduce gradients in fp32 for bfloat16 data type.[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-------arguments.py:636] : using torch.bfloat16 for parameters ...[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1021] : ------------------------ arguments ------------------------[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   account_for_embedding_in_pipeline_split ......... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   account_for_loss_in_pipeline_split .............. False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   accumulate_allreduce_grads_in_fp32 .............. True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   adam_beta1 ...................................... 0.9[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   adam_beta2 ...................................... 0.95[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   adam_eps ........................................ 1e-08[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   add_bias_linear ................................. False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   add_position_embedding .......................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   add_qkv_bias .................................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   adlr_autoresume ................................. False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   adlr_autoresume_interval ........................ 1000[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   align_grad_reduce ............................... True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   align_param_gather .............................. False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   app_tag_run_name ................................ None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   app_tag_run_version ............................. 0.0.0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   apply_layernorm_1p .............................. False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   apply_query_key_layer_scaling ................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   apply_residual_connection_post_layernorm ........ False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   apply_rope_fusion ............................... True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   async_save ...................................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   async_tensor_model_parallel_allreduce ........... True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   attention_backend ............................... auto[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   attention_dropout ............................... 0.0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   attention_softmax_in_fp32 ....................... True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   attn_warmup ..................................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   auto_continue_train ............................. False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   auto_detect_ckpt_format ......................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   barrier_with_L1_time ............................ True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   bert_binary_head ................................ True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   bert_embedder_type .............................. megatron[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   bert_load ....................................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   bf16 ............................................ True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   bias_dropout_fusion ............................. True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   bias_gelu_fusion ................................ False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   bias_swiglu_fusion .............................. True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   biencoder_projection_dim ........................ 0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   biencoder_shared_query_context_model ............ False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   block_data_path ................................. None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   calc_ft_timeouts ................................ False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   calculate_per_token_loss ........................ False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   check_for_large_grads ........................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   check_for_nan_in_loss_and_grad .................. True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   check_for_spiky_loss ............................ False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   check_weight_hash_across_dp_replicas_interval ... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   ckpt_assume_constant_structure .................. False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   ckpt_convert_format ............................. None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   ckpt_convert_save ............................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   ckpt_convert_update_legacy_dist_opt_format ...... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   ckpt_format ..................................... torch[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   ckpt_fully_parallel_load ........................ False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   ckpt_fully_parallel_save ........................ True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   ckpt_fully_parallel_save_deprecated ............. False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   ckpt_step ....................................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   classes_fraction ................................ 1.0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   clip_grad ....................................... 1.0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   clone_scatter_output_in_embedding ............... True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   config_logger_dir ............................... [0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   consumed_train_samples .......................... 0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   consumed_valid_samples .......................... 0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   context_parallel_size ........................... 1[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   cp_comm_type .................................... p2p[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   create_attention_mask_in_dataloader ............. True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   cross_entropy_fusion_impl ....................... native[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   cross_entropy_loss_fusion ....................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   cuda_graph_scope ................................ full[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   cuda_graph_warmup_steps ......................... 3[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   data_args_path .................................. None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   data_cache_path ................................. None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   data_parallel_random_init ....................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   data_parallel_sharding_strategy ................. no_shard[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   data_parallel_size .............................. 8[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   data_path ....................................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   data_per_class_fraction ......................... 1.0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   data_sharding ................................... True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   dataloader_type ................................. cyclic[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   ddp_average_in_collective ....................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   ddp_bucket_size ................................. None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   ddp_num_buckets ................................. None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   ddp_pad_buckets_for_high_nccl_busbw ............. False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   decoder_first_pipeline_num_layers ............... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   decoder_last_pipeline_num_layers ................ None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   decoder_num_layers .............................. None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   decoder_pipeline_manual_split_list .............. None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   decoder_seq_length .............................. None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   decoupled_lr .................................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   decoupled_min_lr ................................ None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   decrease_batch_size_if_needed ................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   defer_embedding_wgrad_compute ................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   deprecated_use_mcore_models ..................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   deterministic_mode .............................. False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   dino_bottleneck_size ............................ 256[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   dino_freeze_last_layer .......................... 1[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   dino_head_hidden_size ........................... 2048[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   dino_local_crops_number ......................... 10[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   dino_local_img_size ............................. 96[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   dino_norm_last_layer ............................ False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   dino_teacher_temp ............................... 0.07[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   dino_warmup_teacher_temp ........................ 0.04[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   dino_warmup_teacher_temp_epochs ................. 30[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   disable_compile_dependencies .................... True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   disable_last_saving ............................. True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   disable_primus_topk_router ...................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   disable_profiler_activity_cpu ................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   disable_straggler_on_startup .................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   disable_tensorboard ............................. True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   disable_wandb ................................... True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   dist_ckpt_format_deprecated ..................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   dist_ckpt_strictness ............................ assume_ok_unexpected[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   distribute_saved_activations .................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   distributed_backend ............................. nccl[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   distributed_timeout_minutes ..................... 60[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   dump_pp_data .................................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   embedding_path .................................. None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   empty_unused_memory_level ....................... 0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   enable_cuda_graph ............................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   enable_ft_package ............................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   enable_gloo_process_groups ...................... True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   enable_one_logger ............................... True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   enable_primus_turbo ............................. True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   enable_turbo_attention_float8 ................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   enable_turbo_gemm_float8 ........................ False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   encoder_num_layers .............................. 32[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   encoder_pipeline_model_parallel_size ............ 0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   encoder_seq_length .............................. 8192[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   encoder_tensor_model_parallel_size .............. 0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   end_weight_decay ................................ 0.1[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   eod_mask_loss ................................... True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   error_injection_rate ............................ 0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   error_injection_type ............................ transient_error[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   eval_interval ................................... 1000[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   eval_iters ...................................... 0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   evidence_data_path .............................. None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   exit_duration_in_mins ........................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   exit_interval ................................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   exit_on_missing_checkpoint ...................... True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   exit_signal_handler ............................. False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   exp_avg_dtype ................................... torch.float32[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   exp_avg_sq_dtype ................................ torch.float32[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   expert_model_parallel_size ...................... 1[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   expert_tensor_parallel_size ..................... 1[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   external_cuda_graph ............................. False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   ffn_hidden_size ................................. 14336[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   file_sink_level ................................. DEBUG[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   finetune ........................................ False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   flash_decode .................................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   fp16 ............................................ False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   fp16_lm_cross_entropy ........................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   fp32_residual_connection ........................ False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   fp8 ............................................. None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   fp8_amax_compute_algo ........................... max[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   fp8_amax_history_len ............................ 1024[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   fp8_interval .................................... 1[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   fp8_margin ...................................... 0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   fp8_param_gather ................................ False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   fp8_recipe ...................................... delayed[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   fp8_wgrad ....................................... True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   framework ....................................... megatron[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   fused_padded_mla_attention ...................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   global_batch_size ............................... 128[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   grad_reduce_in_bf16 ............................. False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   gradient_accumulation_fusion .................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   gradient_reduce_div_fusion ...................... True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   group_query_attention ........................... True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   head_lr_mult .................................... 1.0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   heterogeneous_layers_config_encoded_json ........ None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   heterogeneous_layers_config_path ................ None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   hidden_dropout .................................. 0.0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   hidden_size ..................................... 4096[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   hierarchical_context_parallel_sizes ............. None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   hybrid_attention_ratio .......................... 0.0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   hybrid_mlp_ratio ................................ 0.0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   hybrid_override_pattern ......................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   hysteresis ...................................... 2[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   ict_head_size ................................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   ict_load ........................................ None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   img_h ........................................... 224[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   img_w ........................................... 224[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   indexer_batch_size .............................. 128[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   indexer_log_interval ............................ 1000[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   inference_batch_times_seqlen_threshold .......... -1[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   inference_dynamic_batching ...................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   inference_dynamic_batching_buffer_guaranteed_fraction  0.2[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   inference_dynamic_batching_buffer_overflow_factor  None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   inference_dynamic_batching_buffer_size_gb ....... 40.0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   inference_dynamic_batching_max_requests_override  None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   inference_dynamic_batching_max_tokens_override .. None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   inference_max_requests .......................... 8[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   inference_max_seq_length ........................ 2560[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   inference_rng_tracker ........................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   init_method_std ................................. 0.008[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   init_method_xavier_uniform ...................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   init_model_with_meta_device ..................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   initial_loss_scale .............................. 4294967296[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   inprocess_restart ............................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   is_hybrid_model ................................. False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   iter_per_epoch .................................. 1250[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   iterations_to_skip .............................. [][0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   keep_fp8_transpose_cache_when_using_custom_fsdp . False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   kv_channels ..................................... 128[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   kv_lora_rank .................................... 32[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   lazy_mpu_init ................................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   load ............................................ None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   local_rank ...................................... 0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   log_avg_reset_interval .......................... 50[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   log_avg_skip_iterations ......................... 2[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   log_batch_size_to_tensorboard ................... True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   log_interval .................................... 1[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   log_learning_rate_to_tensorboard ................ True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   log_loss_scale_to_tensorboard ................... True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   log_memory_to_tensorboard ....................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   log_num_zeros_in_grad ........................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   log_params_norm ................................. False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   log_progress .................................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   log_straggler ................................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   log_throughput .................................. True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   log_timers_to_tensorboard ....................... True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   log_validation_ppl_to_tensorboard ............... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   log_world_size_to_tensorboard ................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   logging_level ................................... 10[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   loss_scale ...................................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   loss_scale_window ............................... 1000[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   lr .............................................. 1e-05[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   lr_decay_iters .................................. None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   lr_decay_samples ................................ None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   lr_decay_style .................................. cosine[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   lr_warmup_fraction .............................. None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   lr_warmup_init .................................. 0.0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   lr_warmup_iters ................................. 2[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   lr_warmup_samples ............................... 0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   lr_wsd_decay_iters .............................. None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   lr_wsd_decay_samples ............................ None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   lr_wsd_decay_style .............................. exponential[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   main_grads_dtype ................................ torch.float32[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   main_params_dtype ............................... torch.float32[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   make_vocab_size_divisible_by .................... 128[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   manual_gc ....................................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   manual_gc_eval .................................. False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   manual_gc_interval .............................. 1[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   mask_factor ..................................... 1.0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   mask_prob ....................................... 0.15[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   mask_type ....................................... random[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   masked_softmax_fusion ........................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   max_position_embeddings ......................... 8192[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   max_tokens_to_oom ............................... 12000[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   memory_snapshot_path ............................ snapshot.pickle[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   merge_file ...................................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   micro_batch_size ................................ 2[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   microbatch_group_size_per_vp_stage .............. None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   min_loss_scale .................................. 1.0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   min_lr .......................................... 0.0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   mmap_bin_files .................................. True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   mock_data ....................................... True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_aux_loss_coeff .............................. 0.0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_enable_deepep ............................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_expert_capacity_factor ...................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_extended_tp ................................. False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_ffn_hidden_size ............................. None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_grouped_gemm ................................ False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_input_jitter_eps ............................ None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_layer_freq .................................. 1[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_layer_recompute ............................. False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_pad_expert_input_to_capacity ................ False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_per_layer_logging ........................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_permute_fusion .............................. False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_router_bias_update_rate ..................... 0.001[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_router_dtype ................................ None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_router_enable_expert_bias ................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_router_force_load_balancing ................. False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_router_group_topk ........................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_router_load_balancing_type .................. aux_loss[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_router_num_groups ........................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_router_pre_softmax .......................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_router_score_function ....................... softmax[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_router_topk ................................. 2[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_router_topk_scaling_factor .................. None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_shared_expert_intermediate_size ............. None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_shared_expert_overlap ....................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_token_dispatcher_type ....................... allgather[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_token_drop_policy ........................... probs[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_use_fused_router_with_aux_score ............. False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_use_legacy_grouped_gemm ..................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_use_upcycling ............................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_z_loss_coeff ................................ None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   mscale .......................................... 1.0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   mscale_all_dim .................................. 1.0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   mtp_loss_scaling_factor ......................... 0.1[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   mtp_num_layers .................................. None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   multi_latent_attention .......................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   name ............................................ pre_trainer[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   nccl_communicator_config_path ................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   no_fp8_weight_transpose_cache ................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   no_load_optim ................................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   no_load_rng ..................................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   no_persist_layer_norm ........................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   no_save_optim ................................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   no_save_rng ..................................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   non_persistent_ckpt_type ........................ None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   non_persistent_global_ckpt_dir .................. None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   non_persistent_local_ckpt_algo .................. fully_parallel[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   non_persistent_local_ckpt_dir ................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   non_persistent_save_interval .................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   norm_epsilon .................................... 1e-06[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   normalization ................................... RMSNorm[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   num_attention_heads ............................. 32[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   num_channels .................................... 3[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   num_classes ..................................... 1000[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   num_dataset_builder_threads ..................... 1[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   num_distributed_optimizer_instances ............. 1[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   num_experts ..................................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   num_layers ...................................... 32[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   num_layers_per_virtual_pipeline_stage ........... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   num_query_groups ................................ 8[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   num_virtual_stages_per_pipeline_rank ............ None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   num_workers ..................................... 8[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   one_logger_async ................................ False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   one_logger_project .............................. megatron-lm[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   one_logger_run_name ............................. None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   onnx_safe ....................................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   openai_gelu ..................................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   optimizer ....................................... adam[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   optimizer_cpu_offload ........................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   optimizer_offload_fraction ...................... 1.0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   output_bert_embeddings .......................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   overlap_cpu_optimizer_d2h_h2d ................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   overlap_grad_reduce ............................. True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   overlap_p2p_comm ................................ False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   overlap_param_gather ............................ True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   overlap_param_gather_with_optimizer_step ........ False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   override_opt_param_scheduler .................... True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   parallel_output ................................. False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   params_dtype .................................... torch.bfloat16[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   patch_dim ....................................... 16[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   per_split_data_args_path ........................ None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   perform_initialization .......................... True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   pin_cpu_grads ................................... True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   pin_cpu_params .................................. True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   pipeline_model_parallel_comm_backend ............ None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   pipeline_model_parallel_size .................... 1[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   pipeline_model_parallel_split_rank .............. None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   position_embedding_type ......................... rope[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   pretrained_checkpoint ........................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   profile ......................................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   profile_ranks ................................... [0][0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   profile_step_end ................................ 12[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   profile_step_start .............................. 10[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   q_lora_rank ..................................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   qk_head_dim ..................................... 128[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   qk_layernorm .................................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   qk_pos_emb_head_dim ............................. 64[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   query_in_block_prob ............................. 0.1[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   rampup_batch_size ............................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   rank ............................................ 0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   recompute_granularity ........................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   recompute_method ................................ None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   recompute_num_layers ............................ None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   record_memory_history ........................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   replication ..................................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   replication_factor .............................. None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   replication_jump ................................ None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   rerun_mode ...................................... disabled[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   reset_attention_mask ............................ False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   reset_position_ids .............................. False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   result_rejected_tracker_filename ................ None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   retriever_report_topk_accuracies ................ [][0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   retriever_score_scaling ......................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   retriever_seq_length ............................ 256[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   retro_add_retriever ............................. False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   retro_attention_gate ............................ 1[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   retro_cyclic_train_iters ........................ None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   retro_encoder_attention_dropout ................. 0.1[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   retro_encoder_hidden_dropout .................... 0.1[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   retro_encoder_layers ............................ 2[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   retro_num_neighbors ............................. 2[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   retro_num_retrieved_chunks ...................... 2[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   retro_project_dir ............................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   retro_verify_neighbor_count ..................... True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   rope_scaling_factor ............................. 8.0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   rotary_base ..................................... 500000[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   rotary_interleaved .............................. False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   rotary_percent .................................. 1.0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   rotary_scaling_factor ........................... 40[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   rotary_seq_len_interpolation_factor ............. None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   run_workload_inspector_server ................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   s3_cache_path ................................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   sample_rate ..................................... 1.0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   save ............................................ /shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/output/amd/root/llama3.1_8B-pretrain/checkpoints[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   save_interval ................................... 20000[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   scatter_gather_tensors_in_pipeline .............. True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   seed ............................................ 1234[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   seq_length ...................................... 8192[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   sequence_parallel ............................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   sgd_momentum .................................... 0.9[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   short_seq_prob .................................. 0.1[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   sink_level ...................................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   skip_train ...................................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   skipped_train_samples ........................... 0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   spec ............................................ None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   split ........................................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   squared_relu .................................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   standalone_embedding_stage ...................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   start_weight_decay .............................. 0.1[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   stderr_sink_level ............................... DEBUG[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   straggler_ctrlr_port ............................ 65535[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   straggler_minmax_count .......................... 1[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   suggested_communication_unit_size ............... 400000000[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   swiglu .......................................... True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   swin_backbone_type .............................. tiny[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   te_rng_tracker .................................. False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tensor_model_parallel_size ...................... 1[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tensorboard_dir ................................. None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tensorboard_log_interval ........................ 1[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tensorboard_queue_size .......................... 1000[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   test_data_path .................................. None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   test_mode ....................................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tiktoken_num_special_tokens ..................... 1000[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tiktoken_pattern ................................ None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tiktoken_special_tokens ......................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   timing_log_level ................................ 0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   timing_log_option ............................... minmax[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   titles_data_path ................................ None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tokenizer_model ................................. meta-llama/Llama-3.1-8B[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tokenizer_type .................................. Llama3Tokenizer[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tp_comm_bootstrap_backend ....................... nccl[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tp_comm_bulk_dgrad .............................. True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tp_comm_bulk_wgrad .............................. True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tp_comm_overlap ................................. False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tp_comm_overlap_ag .............................. True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tp_comm_overlap_cfg ............................. None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tp_comm_overlap_rs .............................. True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tp_comm_overlap_rs_dgrad ........................ False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tp_comm_split_ag ................................ True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tp_comm_split_rs ................................ True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   train_data_path ................................. None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   train_iters ..................................... 50[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   train_samples ................................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   train_sync_interval ............................. None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   trainable ....................................... True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   transformer_impl ................................ transformer_engine[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   transformer_pipeline_model_parallel_size ........ 1[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   untie_embeddings_and_output_weights ............. True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_checkpoint_args ............................. False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_checkpoint_opt_param_scheduler .............. False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_cpu_initialization .......................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_custom_fsdp ................................. False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_deprecated_20241209_moe_layer ............... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_dist_ckpt ................................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_dist_ckpt_deprecated ........................ False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_distributed_optimizer ....................... True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_flash_attn .................................. True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_legacy_models ............................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_mp_args_from_checkpoint_args ................ False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_one_sent_docs ............................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_persistent_ckpt_worker ...................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_precision_aware_optimizer ................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_pytorch_profiler ............................ False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_ring_exchange_p2p ........................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_rocm_mem_info ............................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_rocm_mem_info_iters ......................... [1, 2][0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_rope_scaling ................................ False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_rotary_position_embeddings .................. None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_tokenizer_model_from_checkpoint_args ........ True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_torch_fsdp2 ................................. False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_torch_optimizer_for_cpu_offload ............. False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_tp_pp_dp_mapping ............................ False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_turbo_attention ............................. True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_turbo_column_parallel_linear ................ False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_turbo_column_parallel_linear_torch .......... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_turbo_grouped_mlp ........................... True[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_turbo_layer_norm_column_parallel_linear ..... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_turbo_row_parallel_linear ................... False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   v_head_dim ...................................... 128[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   valid_data_path ................................. None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   variable_seq_lengths ............................ False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   virtual_pipeline_model_parallel_size ............ None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   vision_backbone_type ............................ vit[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   vision_pretraining .............................. False[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   vision_pretraining_type ......................... classify[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   vocab_extra_ids ................................. 0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   vocab_file ...................................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   vocab_size ...................................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   wandb_entity .................................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   wandb_exp_name .................................. None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   wandb_project ................................... None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   wandb_save_dir .................................. None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   weight_decay .................................... 0.1[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   weight_decay_incr_style ......................... constant[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   wgrad_deferral_limit ............................ 0[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   world_size ...................................... 8[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   yaml_cfg ........................................ None[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1029] : -------------------- end of arguments ---------------------[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:975] : -monkey patch megatron.training.global_vars._set_wandb_writer...[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:980] : -set_global_variables...[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:985] : -build_tokenizer...[0m
[[32m20250911 02:07:41[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[--------tokenizer.py:40] : -building Llama3Tokenizer tokenizer...[0m
[[32m20250911 02:07:42[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[--------tokenizer.py:63] :  > padded vocab (size: 128256) with 0 dummy tokens (new size: 128256)[0m
RerunStateMachine initialized in mode disabled
[[32m20250911 02:07:42[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[--------trainer.py:1038] : -lazy_mpu_init:     None[0m
[[32m20250911 02:07:42[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[--------trainer.py:1015] : -initialize_distributed...[0m
[[32m20250911 02:07:42[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------initialize.py:315] : > initializing torch distributed ...[0m
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[[32m20250911 02:07:42[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------initialize.py:366] : > initialized tensor model parallel with size 1[0m
[[32m20250911 02:07:42[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[------initialize.py:370] : > initialized pipeline model parallel with size 1[0m
[[32m20250911 02:07:42[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[--------trainer.py:1019] : -seeds:             1234[0m
[[32m20250911 02:07:45[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:596] : time to initialize megatron (seconds): 4.253[0m
[[32m20250911 02:07:45[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:364] : [after megatron is initialized] datetime: 2025-09-11 02:07:45 [0m
[[32m20250911 02:07:45[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:798] : -setup_model_and_optimizer...[0m
/shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM/megatron/core/models/gpt/gpt_layer_specs.py:94: UserWarning: The fp8 argument in "get_gpt_layer_with_transformer_engine_spec" has been deprecated and will be removed soon. Please update your code accordingly.
  warnings.warn(
[[32m20250911 02:07:45[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[--------trainer.py:1093] : use te backend...[0m
[[32m20250911 02:07:45[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[--------trainer.py:1095] : -run get_model[0m
[[32m20250911 02:07:45[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:364] : building GPT model ...[0m
/shared/amdgpu/home/xiaoming_peng_qle/workspace/dev/Primus-CLI/third_party/Megatron-LM/megatron/core/models/gpt/gpt_layer_specs.py:94: UserWarning: The fp8 argument in "get_gpt_layer_with_transformer_engine_spec" has been deprecated and will be removed soon. Please update your code accordingly.
  warnings.warn(
[[32m20250911 02:07:45[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-------training.py:1050] :  > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 8030261248[0m
[[32m20250911 02:07:45[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[--------trainer.py:1097] : [DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-31): 32 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
              (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): IdentityOp()
            (mlp): MLP(
              (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
              (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
    )
  )
)][0m
[[32m20250911 02:07:45[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[--------trainer.py:1111] : -run get_megatron_optimizer[0m
[[32m20250911 02:07:46[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:364] : [after model, optimizer, and learning rate scheduler are built] datetime: 2025-09-11 02:07:46 [0m
[[32m20250911 02:07:46[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:364] : > building train, validation, and test datasets ...[0m
[[32m20250911 02:07:46[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:364] :  > datasets target sizes (minimum size):[0m
[[32m20250911 02:07:46[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:364] :     train:      6400[0m
[[32m20250911 02:07:46[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:364] :     validation: 0[0m
[[32m20250911 02:07:46[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:364] :     test:       0[0m
[[32m20250911 02:07:46[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:904] : > building train, validation, and test datasets for GPT ...[0m
Unable to save MockGPTDataset indexes because path_to_cache is None
Unable to save MockGPTDataset indexes because path_to_cache is None
Unable to save MockGPTDataset indexes because path_to_cache is None
[[32m20250911 02:07:46[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:909] : > finished creating GPT datasets ...[0m
[[32m20250911 02:07:46[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:364] : [after dataloaders are built] datetime: 2025-09-11 02:07:46 [0m
[[32m20250911 02:07:46[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[---------trainer.py:851] : done with setup ...[0m
[[32m20250911 02:07:46[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[--------trainer.py:1241] : training ...[0m
[[32m20250911 02:07:46[0m][[36mrank-0/8[0m][[1mINFO [0m] [1m[--------trainer.py:1381] : Setting rerun_state_machine.current_iteration to 0...[0m
[[32m20250911 02:07:46[0m][[36mrank-7/8[0m][[34m[1mDEBUG[0m] [34m[1m[----------timers.py:417] : (min, max) time across ranks (ms):
    model-and-optimizer-setup ......................: (448.81, 517.20)
    train/valid/test-data-iterators-setup ..........: (14.33, 15.59)[0m
[[32m20250911 02:07:46[0m][[36mrank-0/8[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:364] : [before the start of training step] datetime: 2025-09-11 02:07:46 [0m
