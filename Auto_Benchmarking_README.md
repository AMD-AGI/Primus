<img width="1024" height="468" alt="image" src="https://github.com/user-attachments/assets/f1b2bf61-d612-4e62-bac4-ac115928632a" />



An interactive bash script for automated benchmarking of LLMs on AMD GPUs (MI300X/MI355X) using Megatron or TorchTitan backends supported through Primus.

---

## üöÄ Quick Start

### Step 1: Pull and Launch the Container

```bash
docker pull YOUR_IMAGE
docker run -it \
  --device /dev/dri \
  --device /dev/kfd \
  --network host \
  --ipc host \
  --group-add video \
  --cap-add SYS_PTRACE \
  --security-opt seccomp=unconfined \
  --privileged \
  -v $HOME/.ssh:/root/.ssh \
  --name IMAGE_NAME \
  YOUR_IMAGE
```

### Step 2: Navigate to Primus Directory

```bash
cd /workspace/Primus
```

### Step 3: Run the Benchmarking Tool

```bash
bash run_primus_auto_benchmarking_tool.sh
```

---

## üìã Features

- ‚úÖ **Interactive Menu System** - User-friendly CLI with color-coded outputs
- ‚úÖ **Multi-Backend Support** - Compatible with Megatron and TorchTitan
- ‚úÖ **Batch Processing** - Run multiple model configurations sequentially
- ‚úÖ **Configuration Editing** - Edit YAML configs before execution
- ‚úÖ **Parameter Overrides** - Override specific parameters without editing files
- ‚úÖ **Auto Device Detection** - Automatically detects AMD MI300X/MI355X GPUs
- ‚úÖ **Comprehensive Logging** - Timestamped logs for each benchmark run
- ‚úÖ **Environment Management** - Custom environment variable support

---

## üìñ Complete Walkthrough

### 1Ô∏è‚É£ Backend Selection

When you launch the tool, you'll first choose the backend framework:

```
‚òÖ Choose Backend:
  ‚óè 1) megatron
  ‚óè 2) torchtitan

‚ûú Enter number or name:
```

**Options:**
- Enter `1` or `megatron` for Megatron backend
- Enter `2` or `torchtitan` for TorchTitan backend

---

### 2Ô∏è‚É£ Model Configuration Selection

The tool scans for available YAML configuration files in the selected backend directory:

```
‚òÖ Available Model Configs: (megatron)
  ‚óè 1) llama3_8b.yaml
  ‚óè 2) llama3_70b.yaml
  ‚óè 3) gpt3_175b.yaml

‚ûú Select config number(s) (comma-separated, range, or 'all'):
(Examples: 1,3,5 or 4-8 or all)
```

**Selection Options:**
- **Single:** `1` - Select one config
- **Multiple:** `1,3,5` - Select specific configs (comma-separated)
- **Range:** `4-8` - Select a range of configs
- **All:** `all` - Select all available configs

---

### 3Ô∏è‚É£ View Configuration Parameters

Option to preview parameters in your selected configurations:

```
‚òÖ View Configuration Parameters?
‚ûú (y/n):
```

If you choose `y`, the tool displays the contents of each selected YAML file (excluding comments and empty lines).

---

### 4Ô∏è‚É£ Edit Configuration Files

**For Multiple Configs:**
```
‚òÖ Edit any configuration files before running?
‚ûú (y/n):
```

If `y`, you can select which configs to edit:
```
Selected models:
  ‚óè 1) llama3_8b.yaml
  ‚óè 2) llama3_70b.yaml

‚óè Enter model numbers to edit (comma-separated, or 'all'):
‚ûú
```

**For Single Config:**
```
‚òÖ Edit configuration file before running?
‚ûú (y/n):
```

The tool opens the config in your default editor (tries `nano`, `vim`, `vi`, `code`, or `$EDITOR`). Edit, save, and close to continue. Edited configs are saved to the `logs/` directory.

---

### 5Ô∏è‚É£ Override Parameters

Override specific parameters without editing the entire file:

```
‚òÖ Override any parameters?
  (Format: key=value, e.g., batch_size=32)
‚ûú (y/n):
```

If `y`, enter overrides one per line:
```
‚ûú Override (or press Enter to finish): batch_size=32
‚úì Will override: batch_size = 32
‚ûú Override (or press Enter to finish): learning_rate=0.001
‚úì Will override: learning_rate = 0.001
‚ûú Override (or press Enter to finish): [Press Enter]

‚úì 2 parameter(s) will be overridden
```

---

### 6Ô∏è‚É£ Device Detection

The tool automatically detects your AMD GPU:

```
‚òÖ Detecting Device...
  ‚óè Device found: MI300X
‚úì GPU Device: MI300X
```

**Auto-detection methods:**
1. Queries `rocminfo` for "AMD Instinct" devices
2. Falls back to architecture detection (gfx942 ‚Üí MI300X, gfx950 ‚Üí MI355X)

**Manual Selection (if auto-detection fails):**
```
‚úó Could not detect device automatically
‚òÖ Please select Device manually:
  ‚óè 1) MI300X
  ‚óè 2) MI355X

‚ûú Enter number or name:
```

---

### 7Ô∏è‚É£ Device-Specific Environment Variables

Add custom environment variables for your device:

```
‚òÖ Add device-specific environment variables for MI300X?
  (e.g., HSA_OVERRIDE_GFX_VERSION=11.0.0)
‚ûú (y/n):
```

If `y`, enter variables one per line:
```
‚ûú Variable (or press Enter to finish): HSA_OVERRIDE_GFX_VERSION=11.0.0
‚úì Will set: HSA_OVERRIDE_GFX_VERSION=11.0.0
‚ûú Variable (or press Enter to finish): [Press Enter]

‚úì 1 environment variable(s) will be set
```

---

### 8Ô∏è‚É£ Environment Setup

The tool configures the environment:

```
‚òÖ Setting up environment...
‚úì Set HSA_NO_SCRATCH_RECLAIM=1
‚úì Set HSA_OVERRIDE_GFX_VERSION=11.0.0
‚ûú Enter HuggingFace Token: [hidden input]
‚úì HuggingFace token set
```

**Automatic settings:**
- `HSA_NO_SCRATCH_RECLAIM=1` (always set)
- Any custom environment variables you added
- `HF_TOKEN` for HuggingFace authentication

---

### 9Ô∏è‚É£ Benchmark Execution

The tool runs benchmarks for all selected configurations:

```
‚òÖ Starting Benchmark 1/2...
   ‚óè Model: llama3_8b
   ‚óè Backend: megatron
   ‚óè Device: MI300X
   ‚óè Config: logs/llama3_8b_megatron_MI300X_2025-12-11_10-30-45_override.yaml
   ‚óè Log: logs/primus_llama3_8b_megatron_MI300X_2025-12-11_10-30-45.log

‚úì EXP set to: logs/llama3_8b_megatron_MI300X_2025-12-11_10-30-45_override.yaml

[Benchmark output streams here...]

==========================================
 Benchmark 1/2 Completed!
 Log saved at:
   logs/primus_llama3_8b_megatron_MI300X_2025-12-11_10-30-45.log
 Override config saved at:
   logs/llama3_8b_megatron_MI300X_2025-12-11_10-30-45_override.yaml
==========================================

Preparing next benchmark...

[Continues with next benchmark...]
```

**For each benchmark:**
- Applies edited/overridden configurations
- Exports `EXP` environment variable pointing to the config
- Executes `./examples/run_pretrain.sh`
- Streams output to both terminal and log file
- Saves timestamped logs to `logs/` directory

---

### üîü Completion

After all benchmarks complete:

```
=========================================
  All 2 Benchmark(s) Completed!
=========================================
```

---

## üìÅ Output Files

All output files are saved in the `logs/` directory with timestamps:

### Log Files
```
logs/primus_{MODEL}_{BACKEND}_{DEVICE}_{TIMESTAMP}.log
```
Example: `logs/primus_llama3_8b_megatron_MI300X_2025-12-11_10-30-45.log`

### Edited/Override Config Files
```
logs/{MODEL}_{BACKEND}_{DEVICE}_{TIMESTAMP}_edited.yaml
logs/{MODEL}_{BACKEND}_{DEVICE}_{TIMESTAMP}_override.yaml
```

---

## üí° Tips & Best Practices

1. **Batch Processing:** Use `all` or ranges (e.g., `1-5`) to benchmark multiple models efficiently
2. **Parameter Overrides:** Use overrides for quick experiments without modifying config files
3. **Log Management:** Review logs in the `logs/` directory for detailed benchmark results
4. **Environment Variables:** Add device-specific tuning variables for optimal performance
5. **Config Editing:** Edit configs to test different hyperparameters before running

---
