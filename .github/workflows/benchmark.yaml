name: Primus-Benchmark

on:
  workflow_dispatch:
  schedule:
    - cron: '0 0 * * *'

env:
  PRIMUS_TURBO_COMMIT: 5233748e9c5c5795a6484ab31ece47c442d29ec2 # feat(mxfp4): refactor gemm mxfp4 and mxfp8. fuse transpose, hadamard transform and quantization. (#195)
  BENCHMARK_ROOT_DIR: /wekafs/primus/benchmark

jobs:
  run-benchmark-torch:
    env:
      PRIMUS_WORKDIR: /wekafs/primus-data/primus_safe_ci/torch
      GPU_NAME: MI325  # Change this to your GPU model
    runs-on: [primus-lm-bench-torch-wkhbx]
    steps:
      - run: echo "ðŸŽ‰ Begin Primus-Turbo Checkout."
      - name: Set commit hash to env
        run: echo "PRIMUS_TURBO_COMMIT=${PRIMUS_TURBO_COMMIT}" >> $GITHUB_ENV
      - name: Checkout Repo Primus-Turbo
        uses: actions/checkout@v4
        with:
          repository: AMD-AIG-AIMA/Primus-Turbo
          submodules: "recursive"
          path: Primus-Turbo
          ref: ${{ env.PRIMUS_TURBO_COMMIT }}
      - run: echo "Begin Primus-Turbo Install."
      - name: Install Primus-Turbo
        run: |
          mv Primus-Turbo /tmp/
          echo "Primus-Turbo dir: /tmp/Primus-Turbo"
          git config --global --add safe.directory /tmp/Primus-Turbo
          cd /tmp/Primus-Turbo
          start_time=$(date +%s)
          echo "âœ… [Pip install requirements] started at: $(date)"
          mkdir -p ${PRIMUS_WORKDIR}/primus-cache
          MAX_JOBS=128 pip install --cache-dir=${PRIMUS_WORKDIR}/primus-cache --no-build-isolation --no-clean -r requirements.txt
          end_time=$(date +%s)
          elapsed=$((end_time - start_time))
          echo "âœ… [Pip install requirements] ended at: $(date)"
          echo "â±ï¸ [Pip install requirements] Total elapsed time: ${elapsed} seconds"
          start_time=$(date +%s)
          echo "âœ… [build primus-turbo] started at: $(date)"
          pip3 install --no-build-isolation -e . -v
          end_time=$(date +%s)
          elapsed=$((end_time - start_time))
          echo "âœ… [build primus-turbo] ended at: $(date)"
          echo "â±ï¸ [build primus-turbo] Total elapsed time: ${elapsed} seconds"
      - run: echo "ðŸŽ‰ Begin Primus Benchmark."
      - uses: actions/checkout@v4
        with:
          submodules: recursive
      - name: Show Environment Info
        run: |
          echo "Hostname: $(hostname)"
          echo "PWD: $(pwd)"
          echo "HOME: $HOME"
          echo "GITHUB_WORKSPACE: $GITHUB_WORKSPACE"
          echo "Runner Temp Dir: $RUNNER_TEMP"
          echo "Runner Tool Cache: $RUNNER_TOOL_CACHE"
      - name: Install Primus
        run: |
          pip install -r requirements.txt
      - name: Set BENCHMARK_PATH
        run: |
          BENCHMARK_DATE=$(date +%Y%m%d)
          BENCHMARK_DATE_DIR="${BENCHMARK_ROOT_DIR}/${BENCHMARK_DATE}"
          BENCHMARK_LOG_DIR="${BENCHMARK_DATE_DIR}/${GPU_NAME}"
          mkdir -p "${BENCHMARK_LOG_DIR}"
          echo "BENCHMARK_DATE_DIR=${BENCHMARK_DATE_DIR}" >> $GITHUB_ENV
          echo "BENCHMARK_LOG_DIR=${BENCHMARK_LOG_DIR}" >> $GITHUB_ENV
      - name: Run Primus Model Benchmark -- Megatron-LM
        env:
          DATA_PATH: /wekafs/primus-data
          HSA_NO_SCRATCH_RECLAIM: 1
          HF_TOKEN: ${{secrets.HF_TOKEN}}
        timeout-minutes: 240
        continue-on-error: true
        run: |
          echo "run llama2_7B-BF16"
          ./runner/primus-cli direct --log_file "${BENCHMARK_LOG_DIR}/megatron/llama2_7B-BF16.log" \
          -- train pretrain --config examples/megatron/configs/MI300X/llama2_7B-BF16-pretrain.yaml
          echo "run llama2_7B-FP8"
          ./runner/primus-cli direct --log_file "${BENCHMARK_LOG_DIR}/megatron/llama2_7B-FP8.log" \
          -- train pretrain --config examples/megatron/configs/MI300X/llama2_7B-FP8-pretrain.yaml
          echo "run llama2_70B-BF16"
          ./runner/primus-cli direct --log_file "${BENCHMARK_LOG_DIR}/megatron/llama2_70B-BF16.log" \
          -- train pretrain --config examples/megatron/configs/MI300X/llama2_70B-BF16-pretrain.yaml
          echo "run llama3.1_8B-BF16"
          ./runner/primus-cli direct --log_file "${BENCHMARK_LOG_DIR}/megatron/llama3.1_8B-BF16.log" \
          -- train pretrain --config examples/megatron/configs/MI300X/llama3.1_8B-BF16-pretrain.yaml
          echo "run qwen2.5_7B-BF16"
          ./runner/primus-cli direct --log_file "${BENCHMARK_LOG_DIR}/megatron/qwen2.5_7B-BF16.log" \
          -- train pretrain --config examples/megatron/configs/MI300X/qwen2.5_7B-BF16-pretrain.yaml
          echo "run mixtral_8x7B_v0.1-BF16"
          ./runner/primus-cli direct --log_file "${BENCHMARK_LOG_DIR}/megatron/mixtral_8x7B_v0.1-BF16.log" \
          -- train pretrain --config examples/megatron/configs/MI300X/mixtral_8x7B_v0.1-BF16-pretrain.yaml
          echo "run llama3.1_70B-BF16"
          ./runner/primus-cli direct --log_file "${BENCHMARK_LOG_DIR}/megatron/llama3.1_70B-BF16.log" \
          -- train pretrain --config examples/megatron/configs/MI300X/llama3.1_70B-BF16-pretrain.yaml
          echo "run llama3.1_8B-FP8"
          ./runner/primus-cli direct --log_file "${BENCHMARK_LOG_DIR}/megatron/llama3.1_8B-FP8.log" \
          -- train pretrain --config examples/megatron/configs/MI300X/llama3.1_8B-FP8-pretrain.yaml
          echo "run mixtral_8x7B_v0.1-FP8"
          ./runner/primus-cli direct --log_file "${BENCHMARK_LOG_DIR}/megatron/mixtral_8x7B_v0.1-FP8.log" \
          -- train pretrain --config examples/megatron/configs/MI300X/mixtral_8x7B_v0.1-FP8-pretrain.yaml
          echo "run qwen2.5_72B-BF16"
          ./runner/primus-cli direct --log_file "${BENCHMARK_LOG_DIR}/megatron/qwen2.5_72B-BF16.log" \
          -- train pretrain --config examples/megatron/configs/MI300X/qwen2.5_72B-BF16-pretrain.yaml
          echo "run qwen2.5_7B-FP8"
          ./runner/primus-cli direct --log_file "${BENCHMARK_LOG_DIR}/megatron/qwen2.5_7B-FP8.log" \
          -- train pretrain --config examples/megatron/configs/MI300X/qwen2.5_7B-FP8-pretrain.yaml
          echo "run deepseek_v2_lite-BF16"
          ./runner/primus-cli direct --log_file "${BENCHMARK_LOG_DIR}/megatron/deepseek_v2_lite-BF16.log" \
          -- train pretrain --config examples/megatron/configs/MI300X/deepseek_v2_lite-BF16-pretrain.yaml
      - name: Run Primus Model Benchmark -- TorchTitan
        env:
          DATA_PATH: /wekafs/primus-data
          HSA_NO_SCRATCH_RECLAIM: 1
          HF_TOKEN: ${{secrets.HF_TOKEN}}
        timeout-minutes: 240
        continue-on-error: true
        run: |
          echo "run llama3.1_8B-BF16"
          ./runner/primus-cli direct --log_file "${BENCHMARK_LOG_DIR}/torchtitan/llama3.1_8B-BF16.log" \
          -- train pretrain --config examples/torchtitan/configs/MI300X/llama3.1_8B-BF16-pretrain.yaml
          echo "run llama3.1_8B-FP8"
          ./runner/primus-cli direct --log_file "${BENCHMARK_LOG_DIR}/torchtitan/llama3.1_8B-FP8.log" \
          -- train pretrain --config examples/torchtitan/configs/MI300X/llama3.1_8B-FP8-pretrain.yaml
          echo "run qwen3_1.7B"
          ./runner/primus-cli direct --log_file "${BENCHMARK_LOG_DIR}/torchtitan/qwen3_1.7B-pretrain.log" \
          -- train pretrain --config examples/torchtitan/configs/MI300X/qwen3_1.7B-pretrain.yaml
          echo "run llama3.1_70B-BF16"
          ./runner/primus-cli direct --log_file "${BENCHMARK_LOG_DIR}/torchtitan/llama3.1_70B-BF16.log" \
          -- train pretrain --config examples/torchtitan/configs/MI300X/llama3.1_70B-BF16-pretrain.yaml
          echo "run llama3.1_70B-FP8"
          ./runner/primus-cli direct --log_file "${BENCHMARK_LOG_DIR}/torchtitan/llama3.1_70B-FP8.log" \
          -- train pretrain --config examples/torchtitan/configs/MI300X/llama3.1_70B-FP8-pretrain.yaml
          echo "run qwen3_0.6B.log"
          ./runner/primus-cli direct --log_file "${BENCHMARK_LOG_DIR}/torchtitan/qwen3_0.6B.log" \
          -- train pretrain --config examples/torchtitan/configs/MI300X/qwen3_0.6B-pretrain.yaml
          echo "run qwen3_32B.log"
          ./runner/primus-cli direct --log_file "${BENCHMARK_LOG_DIR}/torchtitan/qwen3_32B.log" \
          -- train pretrain --config examples/torchtitan/configs/MI300X/qwen3_32B-pretrain.yaml
      - name: Generate Summary Report
        run: |
          echo "Generate Summary Report"
          python3 tools/daily/daily_report.py --report-csv-path "${BENCHMARK_DATE_DIR}/summary.csv" --benchmark-log-dir "${BENCHMARK_LOG_DIR}"
      - name: Clean
        run: |
          rm -rf ${PRIMUS_WORKDIR}/Primus-Turbo
          rm -rf ${PRIMUS_WORKDIR}/Primus
